{"docstore/metadata": {"aef3d136-e810-4a01-890d-83b6e42d8194": {"doc_hash": "5f1a8ef2a58cae177121f5a5285824248ea849e305786c38e54c44cd0ddce955"}, "8712f75a-4d8d-48eb-8ab5-519f872c10a5": {"doc_hash": "8b4bdae036a4b2d4d3f0ea247854586910132eb7a29b9468a5ce2c9e46f606fb"}, "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc": {"doc_hash": "2b1ef267c6dfec875feea279e5e671e29c86c7ba0b069a7094064ac4e08d6644"}, "cad11c4f-1cb8-424c-b402-6bfb80fa14a8": {"doc_hash": "656ccdb23406c288bf9f86dbc8f767de0cfb208e3765279f9a24022f558de9a0"}, "65828a06-9dcc-4816-9fe2-c6d04307f32a": {"doc_hash": "b8a42df68288c05f86876f39d85af9a2be5beb103f75de967cfd0c2b468d98c5"}, "8ec0be30-36cf-4e97-9b25-8f4842f64eb6": {"doc_hash": "53c436961ebd427c697821e9f85d74b0843cac947e108cbfeff122e31957700b"}, "ac142b52-8eb9-4888-b5a3-25287bfef816": {"doc_hash": "63c0986f11e3f929add0ccc6a5a52b7e72603f4f161ab90c8521aaaaa7fc2382"}, "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a": {"doc_hash": "94f19d830c8d9b7d45b37c64f91c295ea876a768d44b7c82c06a2bcb7ec1acb7"}, "c325e890-cc06-41dc-bb94-176cace6b10a": {"doc_hash": "b44e90a62c0a71304512f1d55245086c45510a78d0081fa4b2d67dc1267b2a18"}, "8e35081f-bd3c-4909-a3a0-8c2c7e327df1": {"doc_hash": "bb71be7b1d1930edc60218c61b015fbb7009ec948d487349e3ec5565054c2a0e"}, "8c901dae-b4d8-461f-b233-aa9dbe34ca9c": {"doc_hash": "1bc2de3cdadaa1a571984fbb492c6734dba819a39f349d3621207be9fd21af99"}, "c12de919-96a7-44bc-9d9a-0cc878ae3018": {"doc_hash": "3f40b49dc0100dadde0bc593221bf9e41737fed09ba68d04dc903492b5505fd8"}, "9a3183f3-76e1-4826-a144-f839e72a2072": {"doc_hash": "e651456fb488c659dd20369f930a3707598369e928a4ecf89738f95203ae362b"}, "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d": {"doc_hash": "0a7ca0df5a47a9f3b00e0ba185e4d1ba460cc9d5490c378f20b55a0a010a66a0"}, "eb078313-8dfc-4f8b-b135-99bf24d6949b": {"doc_hash": "3d9bc77c0fb2bd4b8a2127f0f02742bf6f45a0de674615544206859381cf0716", "ref_doc_id": "aef3d136-e810-4a01-890d-83b6e42d8194"}, "0d9c38a4-bacf-4c86-943f-b6f309a04c03": {"doc_hash": "8eb082e34c231b5eaf6783e2f591a6eb2b32fd43682490fd19db5c1b5d8a6a09", "ref_doc_id": "aef3d136-e810-4a01-890d-83b6e42d8194"}, "2574a6e4-128c-4b72-be10-b3db7e1599c0": {"doc_hash": "20a205e5bb810981c1253ea866a296c5620c85d8c05252393f984b7c51f26d4e", "ref_doc_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5"}, "4a19e693-31c6-494d-85c2-fa2068708566": {"doc_hash": "2570e4c4a93eff7df6e066d45f934fc558026606e76680ac44902169afef7198", "ref_doc_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5"}, "2a37f814-f9e3-45b9-98fd-5d0da4ecf6ae": {"doc_hash": "47ee237fcc0032b02869b2581b6b2ce07bd71f9251296b49c8bbbf0fa031e8ac", "ref_doc_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5"}, "e1388bac-3ed2-44ad-8f6e-828eb88104fc": {"doc_hash": "0110c13b1ea59dc6ab0ffda1fc12931d619faf95ecc6694f62b5335fbfe8b3dc", "ref_doc_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc"}, "314c83b2-1f4f-462f-a9df-fe7092dae963": {"doc_hash": "e78120a9cae7c843dd765ac966b9ff0cb768052e217eeadc244feb02d176ebca", "ref_doc_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc"}, "ffdcc9e5-0b39-4810-9fd2-4e1e047f9d93": {"doc_hash": "4cfee34b84ef13043300b7cedb63320dc4fc37892db7014b6a3ba37b947304ed", "ref_doc_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc"}, "90a4a35a-5af3-4b50-8ba4-3ea57a9a648f": {"doc_hash": "402828607b4ece4557a4ca0612de93967f3e73af9b8c68467053afc162d113d5", "ref_doc_id": "cad11c4f-1cb8-424c-b402-6bfb80fa14a8"}, "b0f04e2d-60e8-48eb-8cbe-2be79efa511a": {"doc_hash": "e6b72a3748edc5e17c1205b6e4ecdb685c890e347558e5e736ee77bea1920ccf", "ref_doc_id": "cad11c4f-1cb8-424c-b402-6bfb80fa14a8"}, "7697aa0e-f7e0-49ba-a9fa-f055ba16c5c1": {"doc_hash": "78c1cd01836ff565fb15bdc134945b87ef5d67dcff96e98d4b453796987de695", "ref_doc_id": "65828a06-9dcc-4816-9fe2-c6d04307f32a"}, "5ee5b3b8-eac7-468a-a175-1d60b9b61465": {"doc_hash": "df1af39de324d865c0f0be796bc572c139b96e23969a799f0d1082600996c6e7", "ref_doc_id": "65828a06-9dcc-4816-9fe2-c6d04307f32a"}, "d263903d-97d5-411d-a83e-05a3c33133d4": {"doc_hash": "ea3e141cd19c7c30d7aec0be6da092a687c0ef47a84b575d1ee858170ccadf40", "ref_doc_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6"}, "6c466e67-ce9d-4a4e-ab96-2c2efde0926f": {"doc_hash": "ccdda8cdc3d8256dda290bcbd48c1618689cda071d9e099e634671d0c4387649", "ref_doc_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6"}, "c732c7a9-eaa6-453c-ae3c-1ed606da68d7": {"doc_hash": "1dfd9248ab5b74572121bfe85ff767823480e7c750f726cecc61167454200ad6", "ref_doc_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6"}, "111df506-7ad6-456a-afbc-2735fb3a9a8f": {"doc_hash": "b6bc58dc7245c6c1ef33e5d7f99275e755a3530ec460c8610639f05fa38e2426", "ref_doc_id": "ac142b52-8eb9-4888-b5a3-25287bfef816"}, "d4215fab-1246-4e21-853d-53d3243b1dcf": {"doc_hash": "51a2b79f50bfb69b978719dc31a1a7248c9d5767315cb30485094bcff27ce399", "ref_doc_id": "ac142b52-8eb9-4888-b5a3-25287bfef816"}, "4cbcc6cb-a133-4f99-8840-4fab42e312eb": {"doc_hash": "8b2f78bca0622ce4d122cb09c2d442143cfe9b1b73833c3b2bbca1a36a59a0bb", "ref_doc_id": "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a"}, "57a9ea42-5b75-4bcc-9244-688421dd01b6": {"doc_hash": "cf72b574746fc32ffec0679b8d2422d0270dd5ee25b632caec19b40bc3e9ed38", "ref_doc_id": "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a"}, "6b17472d-dc4b-46c8-8e97-61feb135c6db": {"doc_hash": "36138714926f84843a673a8cfd9d56841095e900426bc0e11a59f1462ba2268c", "ref_doc_id": "c325e890-cc06-41dc-bb94-176cace6b10a"}, "d932e14b-f4a5-47c2-b590-5f5b2efe89b3": {"doc_hash": "753c7655f519bf5b467c785ebbf1254e6c7abd02d3edce99e171e022d8fe85dc", "ref_doc_id": "c325e890-cc06-41dc-bb94-176cace6b10a"}, "8921507e-616c-4489-b81c-f7b24ff0031a": {"doc_hash": "3f88f43a3dc7ea0761b55aecfa719401cd4d18e9d5a4074a4504a173e3c89934", "ref_doc_id": "8e35081f-bd3c-4909-a3a0-8c2c7e327df1"}, "97398f38-f881-4e86-a3a9-1f62e0bc5bdc": {"doc_hash": "d70bf61355ff0902546f2da56e28960be63bb9eb75c0356441c5bc801bbab1d7", "ref_doc_id": "8e35081f-bd3c-4909-a3a0-8c2c7e327df1"}, "7c0ad5c5-cb17-4ab3-a3b0-3f7661e62d6e": {"doc_hash": "c194aaa4ec685886d1745f5b316ca11f4d7f0a3995e65df3e84ef25cf87631a3", "ref_doc_id": "8c901dae-b4d8-461f-b233-aa9dbe34ca9c"}, "bc8d3c3a-8ae9-4bb3-a8f9-9d8be58b074d": {"doc_hash": "936d06f48a253f85b052814448bb21088c910ef2c29e7c50ff0aa14bf83b0552", "ref_doc_id": "8c901dae-b4d8-461f-b233-aa9dbe34ca9c"}, "ad3c2cc7-4123-4c4c-95db-6e845fb67d31": {"doc_hash": "9d053f79892211dc0fca67912b04244f28773ad26b9f1b3e575d686627cade4c", "ref_doc_id": "c12de919-96a7-44bc-9d9a-0cc878ae3018"}, "43800959-3c1f-4625-8777-69e204f92dba": {"doc_hash": "4ed4aa363c5cd3eba95ad17b017b4eeec251825f20d1cbcd5941d192d7f29ea1", "ref_doc_id": "c12de919-96a7-44bc-9d9a-0cc878ae3018"}, "2e018cb5-4924-430b-a91a-d194015eb6a9": {"doc_hash": "1e7f3e9faea80c6b03e7ccef0e3c1ca120a8a035c68c8033755d526916e16d42", "ref_doc_id": "9a3183f3-76e1-4826-a144-f839e72a2072"}, "ad192068-9a0a-45d0-b8bd-9f24df73b9d3": {"doc_hash": "1b9018655a75a7d4b8a5a148be3d7916103d4b706c8b7a67d3bfa59bb596dcf7", "ref_doc_id": "9a3183f3-76e1-4826-a144-f839e72a2072"}, "83a630a3-1294-4c58-93e8-b34f41497f73": {"doc_hash": "2d3fe7484d446d2607b2a37f4f95670a484b8e49eaaeb410bf6631d4b041bac1", "ref_doc_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d"}, "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2": {"doc_hash": "bd8f427138988a9a997f3653e9dd144eac659c861307e83eec41aef216c142d2", "ref_doc_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d"}, "245770b6-5f44-4dcb-a473-a3aa726177bc": {"doc_hash": "6a2094211c6853fa73e0ecf2603aff9809ee2dfa7c7abf63da2f7d1224af18b7", "ref_doc_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d"}, "c4f0952a-9324-4044-ac57-7584cbae109a": {"doc_hash": "0d85a9e5b6bf804d60c60958a4d5744957bda3b2439da6db390e5f30711ff939", "ref_doc_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d"}}, "docstore/data": {"eb078313-8dfc-4f8b-b135-99bf24d6949b": {"__data__": {"id_": "eb078313-8dfc-4f8b-b135-99bf24d6949b", "embedding": null, "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aef3d136-e810-4a01-890d-83b6e42d8194", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "5f1a8ef2a58cae177121f5a5285824248ea849e305786c38e54c44cd0ddce955", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d9c38a4-bacf-4c86-943f-b6f309a04c03", "node_type": "1", "metadata": {}, "hash": "efb2f7cbd927bd616b19c2c9c3f6911f801897c657a49d0806ce2552690f77f6", "class_name": "RelatedNodeInfo"}}, "text": "Relative Performance Prediction using Few-Shot\nLearning\nArunavo Dey, Aakash Dhakal,\nTanzima Z. Islam\nTexas State University\n{hcs77,nvc22,tanzima }@txstate.eduJae-Seung Yeom,\nTapasya Patki\nLawrence Livermore National Laboratory\n{yeom2,patki1 }@llnl.govDaniel Nichols, Alexander Movsesyan,\nAbhinav Bhatele\nUniversity of Maryland\n{dnicho,amovsesy,bhatele }@umd.edu\nAbstract \u2014High-performance computing system architectures\nare evolving rapidly, making exhaustive data collection for each\narchitecture to build predictive performance models increas-\ningly impractical. Concurrently, the arrival of new applica-\ntions daily necessitates efficient performance prediction methods.\nTraditional data collection can take days or weeks, making\nit more efficient for scientists to leverage existing models to\npredict an application\u2019s performance on new architectures or\nuse data from one application to predict another on the same\narchitecture. The growing heterogeneity in applications and\nresources further complicates the exact matches needed for\neffective knowledge transfer. This work systematically studies\nvarious Machine Learning (ML) models to predict the relative\nperformance of new applications on new platforms using existing\ndata. Our findings demonstrate that few-shot learning using\na few samples significantly enhances cross-platform knowledge\ntransfer, multi-source models outperform single-source models,\nand Large Language Models (LLMs)-generated samples can\neffectively improve knowledge transfer efficacy.\nIndex Terms \u2014Performance Modeling, Machine Learning, Few-\nshot Learning, Large language models (LLM), Cross-platform\nperformance prediction\nI. I NTRODUCTION\nTraditionally, performance modeling of an High Perfor-\nmance Computing (HPC) application is conducted in a data-\ndriven manner by collecting many training samples from\napplications running on multiple platforms. These models aid\nin understanding application behaviors and predicting comple-\ntion times, crucial for effective resource allocation in critical\nsimulations like vaccine development. However, this method is\nplatform-dependent and time-consuming, especially with the\narrival of a new platform every six months. To avoid spending\na long time on performance data collection, scientists often\npredict application performance on new platforms instead of\ndata collection, saving time and resources.\nHowever, the absolute performance of an application de-\npends on interactions with the OS, software stack, and hard-\nware. Existing supervised machine learning approaches [12,\n14] require extensive data collection. We propose a com-\nparative approach using machine learning to predict relative\nperformance, avoiding the need to measure common factors\nlike runtime and OS. Measurements include application pa-\nrameters, machine characteristics, and dynamic interactions.\nWe define the relative performance of an application Xon\nplatform Bcompared to platform AasXB/A.\nThis study systematically examines various ML techniquesfor predicting XB/A. We assess the effectiveness of state-\nof-the-art methods in two scenarios: (1) when at least one\napplication is profiled on all available platforms, facilitating\nsignificant data collection efforts, and (2) when no training ap-\nplication is profiled on all platforms, but each pair has at least\none profiled on both. Predicting relative performance based on\ndata from other applications resembles visual categorization\ntasks such as object recognition and image classification [13].\nIf the source model can adapt using a few samples from the\ntest application during transfer learning, it is called a few-shot\nlearning approach [16].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3653, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d9c38a4-bacf-4c86-943f-b6f309a04c03": {"__data__": {"id_": "0d9c38a4-bacf-4c86-943f-b6f309a04c03", "embedding": null, "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aef3d136-e810-4a01-890d-83b6e42d8194", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "5f1a8ef2a58cae177121f5a5285824248ea849e305786c38e54c44cd0ddce955", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb078313-8dfc-4f8b-b135-99bf24d6949b", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "3d9bc77c0fb2bd4b8a2127f0f02742bf6f45a0de674615544206859381cf0716", "class_name": "RelatedNodeInfo"}}, "text": "Measurements include application pa-\nrameters, machine characteristics, and dynamic interactions.\nWe define the relative performance of an application Xon\nplatform Bcompared to platform AasXB/A.\nThis study systematically examines various ML techniquesfor predicting XB/A. We assess the effectiveness of state-\nof-the-art methods in two scenarios: (1) when at least one\napplication is profiled on all available platforms, facilitating\nsignificant data collection efforts, and (2) when no training ap-\nplication is profiled on all platforms, but each pair has at least\none profiled on both. Predicting relative performance based on\ndata from other applications resembles visual categorization\ntasks such as object recognition and image classification [13].\nIf the source model can adapt using a few samples from the\ntest application during transfer learning, it is called a few-shot\nlearning approach [16]. While most literature focuses on zero-\nshot learning, we hypothesize that adjusting the source model\nwith a few samples using few-shot learning can can enhance\nthe model\u2019s generalizability.\nMoreover, when training samples are scarce, we explore the\napplicability of the LLMs to generate performance samples\nto fill the gap to enable direct knowledge transfer across\napplications. Specifically, in this paper, we investigate the\nfollowing research questions: (1) study the efficacy of sev-\neral regression-based ML techniques when a relatively large\nnumber of labeled training samples are present in transferring\nknowledge; (2) whether a source model built using multiple\napplications\u2019 data is more effective than a single application\u2019s;\n(3) study whether leveraging a few new samples from the tar-\nget application helps to improve ML model\u2019s efficacy further,\nand (4) in the presence of data scarcity, if a Large Language\nModel (LLM) can be used to generate data to alleviate the\nneed for further data collection. We measure the efficacy of\nan ML model using the widely used Mean Square Error (MSE)\nmetric, which calculates how different predictions are from the\nreal values. MSE = 0 indicates a perfect prediction.\nTo summarize our contributions in this paper, we:\n\u2022Evaluate various ML approaches in predicting relative per-\nformance across platforms with sufficient training samples.\n\u2022Propose using a multi-source modeling approach and few-\nshot learning to enhance relative performance prediction\nefficacy.\n\u2022Introduce a novel predictive modeling method using LLMs\nto address data scarcity challenges.\nOur unique HPC performance dataset comprises 3494\nsamples from running 6 applications ( Laghos ,Kripke ,\nSW4lite ,TESTDFFT ,miniVite ,AMG) on three plat-\nforms. Extensive evaluations with this dataset indicate that:", "mimetype": "text/plain", "start_char_idx": 2749, "end_char_idx": 5473, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2574a6e4-128c-4b72-be10-b3db7e1599c0": {"__data__": {"id_": "2574a6e4-128c-4b72-be10-b3db7e1599c0", "embedding": null, "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "8b4bdae036a4b2d4d3f0ea247854586910132eb7a29b9468a5ce2c9e46f606fb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4a19e693-31c6-494d-85c2-fa2068708566", "node_type": "1", "metadata": {}, "hash": "c9347a92da6db262fa84f2970d7e32e5a6ac2a4fd7df83e06ff2c3c82737d5e8", "class_name": "RelatedNodeInfo"}}, "text": "(a) Case 1:Training applications common between the source (A) and destination platforms (B)\n(b) Case 2:No training application common between the source (A) and destination platforms (B). Assumption: f(CA)\u00e0TB/AHardware performancecounter data from test application X On platform ACXATXB/ARelative performance of X on BABg(CA)\u00e0CPCXPf(CP)\u00e0TB/PTXB/PCXAHardware performance counterdata from test application X On platform AHardware performance counterdata from test application X On platform CRelative performance of X on BAPBr, m, nd, e, gXXLLMFig. 1: Overview of the two scenarios that our proposed\napproach addresses.\n(1) gradient-based modeling techniques perform well due to\nconsistent data distribution across applications when suffi-\ncient training samples are present; (2) knowledge transfer\nfrom multiple-application source models is more effective\nthan single-application models; (3) few-shot learning enhances\nrelative performance prediction; and (4) leveraging generative\nAI, especially LLMs, to synthesize performance samples is\neffective when limited training data is present.\nII. M ETHODOLOGY\nA. Problem Formulation\nThe problem of cross-platform relative performance predic-\ntion can be formulated as a knowledge transfer problem in\nML, where a source model trained on measurements from\nvarious applications collected on platforms AandBis used.\nThe source model predicts the performance of an application\nXon platform Busing its hardware performance counters\non platform A. Predicting relative instead of absolute perfor-\nmance enables avoidance of common factors such as runtime,\nOS, and software stack, which would otherwise necessitate an\nexcessive number of performance samples.\nAssuming performance samples with labels are available\nfor a set of applications on platforms AandB, measurements\ncan encompass various factors like application details, machine\nspecifications, and dynamic interactions with the system. For\nthis study, hardware performance counters serve as features. In\na typical scenario, a source model built from these measure-\nments can predict an application\u2019s performance on Busing its\nhardware counters on A. However, in cases of data scarcity\nwhere no application was measured on both platforms, such a\ndirect source model cannot be constructed.\nMathematically, these two scenarios can be summarized as:\n\u2022Case 1: Measurements from at least one application are\navailable on both platforms, AandB. (AppA\u2229AppB\u0338=\u2205).\n\u2022Case 2: No measurements from common applications are\navailable on both platforms, AandB. (AppA\u2229AppB=\u2205).\nB. Case 1: Measurements from at least one application are\navailable on both platforms, AandB\nFigure 1a shows what happens in Case 1. In Case 1,\nlet\u2019s assume we have the hardware performance counter mea-\nsurements from ncommon applications, x1, x2, x3, ..., x non\nplatform A, denoted by C[x1,x2,x3,...,x n]\nA . We also have the\nexecution times for these applications available on platformsAandB, denoted by T[x1,x2,x3,...,x n]\nA andT[x1,x2,x3,...,x n]\nB .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3008, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a19e693-31c6-494d-85c2-fa2068708566": {"__data__": {"id_": "4a19e693-31c6-494d-85c2-fa2068708566", "embedding": null, "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "8b4bdae036a4b2d4d3f0ea247854586910132eb7a29b9468a5ce2c9e46f606fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2574a6e4-128c-4b72-be10-b3db7e1599c0", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "20a205e5bb810981c1253ea866a296c5620c85d8c05252393f984b7c51f26d4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2a37f814-f9e3-45b9-98fd-5d0da4ecf6ae", "node_type": "1", "metadata": {}, "hash": "6d51b146cb88dcbc23c742de536292fd732d83434316581bdfe704f1e5f3d87d", "class_name": "RelatedNodeInfo"}}, "text": "(AppA\u2229AppB\u0338=\u2205).\n\u2022Case 2: No measurements from common applications are\navailable on both platforms, AandB. (AppA\u2229AppB=\u2205).\nB. Case 1: Measurements from at least one application are\navailable on both platforms, AandB\nFigure 1a shows what happens in Case 1. In Case 1,\nlet\u2019s assume we have the hardware performance counter mea-\nsurements from ncommon applications, x1, x2, x3, ..., x non\nplatform A, denoted by C[x1,x2,x3,...,x n]\nA . We also have the\nexecution times for these applications available on platformsAandB, denoted by T[x1,x2,x3,...,x n]\nA andT[x1,x2,x3,...,x n]\nB . We\ncalculate the ground truth values of their relative performance\nonBrelative to AasT[x1,x2,x3,...,x n]\nB/A=T[x1,x2,x3,...,xn]\nB\nT[x1,x2,x3,...,xn]\nA. In\nthis case, we can leverage supervised learning as well as trans-\nfer learning approaches to predict the relative performance of a\ntest application, XB/A using its hardware performance counter\nmeasurements, CX\nA, onA.\nC. Case 2: No measurements from common applications are\navailable on both platforms, AandB\nCase 2 (Figure 1b) is a more challenging problem since\nbuilding a source model to transfer knowledge directly be-\ntween two platforms of interest is not viable due to the\nunavailability of a common application. To simplify this\nscenario within the scope of this work, we assume that\nat least one application exists for each pair of platforms\nwhose hardware performance counters are measured on\nboth platforms. That is, as shown in Figure 1b, the shortest\npath from AtoBwill contain at least one other platform P.\nLet\u2019s assume that xr, xm, xnare the applications with their\ndata available on both AandP. Whereas xd, xe, xgare the\napplications with their data available on both PandB.\nTo address the challenge of transferring knowledge across\nplatforms where a direct knowledge transfer is not viable, we\nproposed a two-step solution.\nStep 1: Data generation: We propose to leverage the\ntabular data generation capabilities of the LLMs to synthesize\nperformance samples for test applications. During the training\nphase, we fine-tune an LLM with C[xr,xm,xn]\nA andC[xr,xm,xn]\nP .\nThis model learns to leverage one application\u2019s features on\none platform to generate the features for the same application\non another platform. During the test time, we leverage the\nfine-tuned LLM to generate performance samples for the test\napplication Xincluding hardware performance counters CX\nP\nand the runtime TX\nPon the platform P.\nStep 2: Building a predictive source model During the\ntraining phase, we build a source model similar to Case 1 with\nxd, xe, xgapplications\u2019 hardware performance counter data\non platform P,C[xd,xe,xg]\nP as features and their ground truth\nvalues of relative performances on Brelative to P,T[xd,xe,xg]\nB/P\nas target labels.", "mimetype": "text/plain", "start_char_idx": 2433, "end_char_idx": 5208, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2a37f814-f9e3-45b9-98fd-5d0da4ecf6ae": {"__data__": {"id_": "2a37f814-f9e3-45b9-98fd-5d0da4ecf6ae", "embedding": null, "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8712f75a-4d8d-48eb-8ab5-519f872c10a5", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "8b4bdae036a4b2d4d3f0ea247854586910132eb7a29b9468a5ce2c9e46f606fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a19e693-31c6-494d-85c2-fa2068708566", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "2570e4c4a93eff7df6e066d45f934fc558026606e76680ac44902169afef7198", "class_name": "RelatedNodeInfo"}}, "text": "During the training\nphase, we fine-tune an LLM with C[xr,xm,xn]\nA andC[xr,xm,xn]\nP .\nThis model learns to leverage one application\u2019s features on\none platform to generate the features for the same application\non another platform. During the test time, we leverage the\nfine-tuned LLM to generate performance samples for the test\napplication Xincluding hardware performance counters CX\nP\nand the runtime TX\nPon the platform P.\nStep 2: Building a predictive source model During the\ntraining phase, we build a source model similar to Case 1 with\nxd, xe, xgapplications\u2019 hardware performance counter data\non platform P,C[xd,xe,xg]\nP as features and their ground truth\nvalues of relative performances on Brelative to P,T[xd,xe,xg]\nB/P\nas target labels. During the testing phase, we leverage the\nsynthesized hardware performance counter values as input to\nthis source model to get the final predictions TX\nB/P.\nIII. E XPERIMENTAL SETUP\nA. Dataset\nWe leverage six different HPC proxy applications on three\nCPU and GPU platforms. Table I and [10] describe the appli-\ncations Laghos ,Kripke ,miniVite ,AMG,SW4lite , and\nTESTDFFT and the data collection process in detail. Table II\ndescribes the set of hardware performance counters used as\nfeatures. Table III describes the specifications of the HPC\nplatforms where data is collected.\nB. Case Studies\nIn this work, we predict the relative performance of various\napplications on Ruby andCorona based on the hardware\nperformance counter data of that application collected on\n2", "mimetype": "text/plain", "start_char_idx": 4463, "end_char_idx": 5976, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1388bac-3ed2-44ad-8f6e-828eb88104fc": {"__data__": {"id_": "e1388bac-3ed2-44ad-8f6e-828eb88104fc", "embedding": null, "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "2b1ef267c6dfec875feea279e5e671e29c86c7ba0b069a7094064ac4e08d6644", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "314c83b2-1f4f-462f-a9df-fe7092dae963", "node_type": "1", "metadata": {}, "hash": "011e54a00d481e52ea0e87356f1fab380590616cce3e8f4b2880e45c5cfdabcd", "class_name": "RelatedNodeInfo"}}, "text": "TABLE I: Description of the applications\nApplication Description\nLaghos FEM for compressible gas dynamics\nKripke 3D Deterministic Particle Transport Code\nminiVite Graph Community Detection\nTESTDFFT Parallel 3D FFT\nSW4lite Seismic Wave Simulation\nAMG Algebraic Multi Grid Solver\nTABLE II: Collected hardware performance counters\nFeature Description\nBranch Intensity Ratio of branch instructions to total instruc-\ntions\nLoad Intensity Ratio of load instructions to total instructions\nStore Intensity Ratio of store instructions to total instruc-\ntions\nL1 Load Misses Load misses from L1 cache\nL1 Store Misses Store misses from L1 cache\nL2 Load Misses Load misses from L2 cache\nL2 Store Misses Store misses from L2 cache\nSingle Floating Point\nIntensityRatio of single precision FP instructions to\ntotal instructions\nDouble Floating Point\nIntensityRatio of double precision FP instructions to\ntotal instructions\nArithmetic Intensity Ratio of integer arithmetic instructions to\ntotal instructions\nI/O Bytes Read Bytes read from IO\nI/O Bytes Written Bytes written to IO\nExtended Page Table Extended page table size\nMemory Stall Memory Stalls\nQuartz for the two scenarios described in Section II. We use\nthe applications with data available on all three platforms\u2014\nQuartz ,Ruby , and Corona \u2014for training a supervised\nsource model.\nFor Case 2, we assume that there is no common training ap-\nplications\u2019 data available on platforms Quartz andCorona .\nHowever, there are common applications that run on platforms\nQuartz andRuby , but not on Corona . Similarly, there\nare common applications that run on Ruby andCorona ,\nbut not on Quartz . In this case, Section IV-E evaluates\nthe effectiveness of the LLM in generating counter data for\nTESTDFFT onCorona . For tabular data generation, we\nleverage the DistillGPT2 [6] LLM from the publicly available\nGreat [2] framework.\nC. Evaluation Metrics and Hyperparameter Tuning\nWe evaluate model performance using MSE as computed in\nEquation 1. We then report the average MSE across 5 trials\nof randomly partitioned train and test splits.\nMSE(y,\u02c6y) =PN\u22121\ni=0(yi\u2212\u02c6yi)2\nN(1)\nHere, yrepresents the ground truth values, \u02c6ydenotes the\npredicted values from the model, and Nis the number of\ntest samples. We use the Keras library for implementing the\nmodels and conduct hyperparameter tuning with SKLearn\u2019s\nGrid Search CV . High MSE indicates poor accuracy. We use\nfeature-wise min-max scaling for all experiments.\nIV. R ESULTS\nA. RQ1: Impact of training a source-model using a single\napplication\nThis experiment aims to evaluate how well a source model\nbuilt from a single application performs when it has seen noTABLE III: Machine Specifications\nMetric Quartz Ruby Corona\nCPU Type Intel Xeon\nE5-2695 v4Intel Xeon\nCLX-8276LAMD Rome\nCores/node 36 56 48\nGPU Support No No Yes\nGPU Type N/A N/A AMD MI50\nGPUs/node N/A N/A 8\nTABLE IV: ML models and their hyperparameters.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2893, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "314c83b2-1f4f-462f-a9df-fe7092dae963": {"__data__": {"id_": "314c83b2-1f4f-462f-a9df-fe7092dae963", "embedding": null, "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "2b1ef267c6dfec875feea279e5e671e29c86c7ba0b069a7094064ac4e08d6644", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1388bac-3ed2-44ad-8f6e-828eb88104fc", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "0110c13b1ea59dc6ab0ffda1fc12931d619faf95ecc6694f62b5335fbfe8b3dc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ffdcc9e5-0b39-4810-9fd2-4e1e047f9d93", "node_type": "1", "metadata": {}, "hash": "3a42b2693ceb4c208eb73417dab534b43c2265e7c0f4cfc8a9c31ede84e85d24", "class_name": "RelatedNodeInfo"}}, "text": "We use the Keras library for implementing the\nmodels and conduct hyperparameter tuning with SKLearn\u2019s\nGrid Search CV . High MSE indicates poor accuracy. We use\nfeature-wise min-max scaling for all experiments.\nIV. R ESULTS\nA. RQ1: Impact of training a source-model using a single\napplication\nThis experiment aims to evaluate how well a source model\nbuilt from a single application performs when it has seen noTABLE III: Machine Specifications\nMetric Quartz Ruby Corona\nCPU Type Intel Xeon\nE5-2695 v4Intel Xeon\nCLX-8276LAMD Rome\nCores/node 36 56 48\nGPU Support No No Yes\nGPU Type N/A N/A AMD MI50\nGPUs/node N/A N/A 8\nTABLE IV: ML models and their hyperparameters.\nModel Hyper-parameters Search range\nXGBoost (XGB), Bagging, Ad-\naboost (ADB), Random Forrest\n(RF), Support Vector Regressor\n(SVR), Decision Tree Regressor\n(DT), Extra Trees (ER)max features [sqrt, log 2]\nLearning Rate [1e\u22125,1e\u22121]\nnestimators [5-100]\nmax depth [5-15]\nloss [squared error, huber, lin-\near, square]\nLinear Regression (LR), Las-\nsoCV (Lasso), Elastic Net CV\n(ENet)cv [2-10]\neps [1e\u22123,1e\u22121]]\ngcv mode [auto, svd, eigen]\nKNNneighbours [1-100]\nmetric [euclidean, manhattan,\nminkowski]\nsamples from the test application. Table V presents results\nfrom using TESTDFFT as the target, and each of Laghos ,\nKripke , andminiVite as the source application separately.\nTABLE V: RQ1: Average MSE when using no adaptation\nduring test-time using TESTDFFT as the target and each of\nLaghos ,Kripke , and miniVite as the source model.", "mimetype": "text/plain", "start_char_idx": 2231, "end_char_idx": 3723, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ffdcc9e5-0b39-4810-9fd2-4e1e047f9d93": {"__data__": {"id_": "ffdcc9e5-0b39-4810-9fd2-4e1e047f9d93", "embedding": null, "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "2b1ef267c6dfec875feea279e5e671e29c86c7ba0b069a7094064ac4e08d6644", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "314c83b2-1f4f-462f-a9df-fe7092dae963", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "e78120a9cae7c843dd765ac966b9ff0cb768052e217eeadc244feb02d176ebca", "class_name": "RelatedNodeInfo"}}, "text": "Table V presents results\nfrom using TESTDFFT as the target, and each of Laghos ,\nKripke , andminiVite as the source application separately.\nTABLE V: RQ1: Average MSE when using no adaptation\nduring test-time using TESTDFFT as the target and each of\nLaghos ,Kripke , and miniVite as the source model.\nModel Single-Application Source Model\nLaghos Kripke miniVite\nRuby Corona Ruby Corona Ruby Corona\nARD 0.143 8.761 0.0125 0.072 0.0001 13.48\nADB 0.147 0.090 0.043 0.195 0.006 13.56\nET 0.134 0.044 0.005 0.160 9.14E-06 13.58\nBR 0.136 0.040 0.015 0.123 1.71E-07 13.45\nSVR 0.102 0.075 0.028 0.072 1.85E-06 14.0\nLasso 0.143 2.13 0.338 0.822 9.21E-05 13.48\nENet 0.143 0.485 0.325 0.773 9.21E-05 13.48\nKNN 0.144 0.032 0.011 0.152 0.0003 13.44\nDT 0.163 0.068 0.073 0.222 0.024 13.70\nRF 0.133 0.055 0.016 0.170 0.004 13.56\nXGB 0.144 0.029 0.008 0.135 1.34E-06 14.06\nFrom Table V, we observe that on average, using Kripke \u2019s\nperformance as the source model yields a 66% improvement\nover Laghos and a 98% improvement over miniVite\nin predicting the relative performance of TESTDFFT . This\nresult can be explained by Figures 2a-d where Kripke and\nTESTDFFT show a similar nature of correlations among\ntheir respective features and target values, which is different\nfrom that of Laghos andminiVite \u2019s. From Table V, we\nalso observe that certain ML models are better for certain\napplication pairs. There is no one consistent winning ML\nmodel. We also observe that it is harder to transfer knowledge\nfromQuartz toCorona . This observation can be explained\nby the fact that Quartz is a CPU-based machine while\nCorona is a GPU-based one. Hence, their architectures are\nsignificantly diverse, which makes it difficult for the CPU-\nbased source model to get a good predictive performance out\nof the box without further fine-tuning.\n3", "mimetype": "text/plain", "start_char_idx": 3424, "end_char_idx": 5235, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "90a4a35a-5af3-4b50-8ba4-3ea57a9a648f": {"__data__": {"id_": "90a4a35a-5af3-4b50-8ba4-3ea57a9a648f", "embedding": null, "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cad11c4f-1cb8-424c-b402-6bfb80fa14a8", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "656ccdb23406c288bf9f86dbc8f767de0cfb208e3765279f9a24022f558de9a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b0f04e2d-60e8-48eb-8cbe-2be79efa511a", "node_type": "1", "metadata": {}, "hash": "63f2d3e5d96ca883df3886efe53d192f21d98ded7d5f549d9d8643abbae34d0e", "class_name": "RelatedNodeInfo"}}, "text": "(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT(a) Laghos(b) Kripke\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT(c) miniVite\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFT\n(a) Laghos(b) Kripke\n(c) Minivite(d) TestDFFTFig. 2: Heatmap with Correlation Matrix of the hardware performance counters of (a) Laghos , (b)Kripke , (c)miniVite ,\nand (d) TESTDFFT onCorona .\nB. RQ2: Impact of fine-tuning a single-source model using\nfew-shot samples from the target application\nIn this experiment, we evaluate the effectiveness of using\nfew-shot samples to adapt single-application source models\nduring test time. For these experiments, we use Laghos as\nthe source and TESTDFFT as the target.\nTABLE VI: RQ2: Average MSE when using a single-source\nmodel and adapting it using few-shot samples. We use\nLaghos as the source and TESTDFFT as the target.\nModel Applications\n1%\nRuby Corona\nARD 0.060 0.005\nADB 0.028 0.007\nET 0.024 0.005\nBR 0.061 0.005\nSVR 0.102 0.075\nLasso 0.031 0.006\nENet 0.032 0.006\nKNN 0.021 0.006\nDT 0.101 0.105\nRF 0.027 0.006\nXGB 0.143 0.038\nFrom Table VI we observe that using as low as 1% samples\nto fine-tune the source model drastically improves its ability\nto generalize over zero-shot. For instance, using 1% few-shot\nsamples can reduce error for the ET and RF models by 82%and 79%, respectively. This result supports our hypothesis that\nusing few-shot learning to adapt the source model can improve\nthe model\u2019s ability to generalize to new scenarios.\nC. RQ3: Impact of training a source-model using multiple\napplications\nIn this section, we evaluate the impact of using a source\nmodel built from multiple applications\u2019 data directly without\nadapting it during test time. Table VII shows results from\nexperiments using a source model built from the data of\nLaghos ,Kripke ,miniVite ,SW4lite , and AMG and\nTESTDFFT as the target application. The results indicate that\nthe accuracy of all models significantly improves when using a\nmulti-source model for prediction, compared to a single-source\nmodel as shown in Table V. This improvement is observed for\nbothRuby andCorona across all models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2341, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0f04e2d-60e8-48eb-8cbe-2be79efa511a": {"__data__": {"id_": "b0f04e2d-60e8-48eb-8cbe-2be79efa511a", "embedding": null, "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cad11c4f-1cb8-424c-b402-6bfb80fa14a8", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "656ccdb23406c288bf9f86dbc8f767de0cfb208e3765279f9a24022f558de9a0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "90a4a35a-5af3-4b50-8ba4-3ea57a9a648f", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "402828607b4ece4557a4ca0612de93967f3e73af9b8c68467053afc162d113d5", "class_name": "RelatedNodeInfo"}}, "text": "This result supports our hypothesis that\nusing few-shot learning to adapt the source model can improve\nthe model\u2019s ability to generalize to new scenarios.\nC. RQ3: Impact of training a source-model using multiple\napplications\nIn this section, we evaluate the impact of using a source\nmodel built from multiple applications\u2019 data directly without\nadapting it during test time. Table VII shows results from\nexperiments using a source model built from the data of\nLaghos ,Kripke ,miniVite ,SW4lite , and AMG and\nTESTDFFT as the target application. The results indicate that\nthe accuracy of all models significantly improves when using a\nmulti-source model for prediction, compared to a single-source\nmodel as shown in Table V. This improvement is observed for\nbothRuby andCorona across all models.\nD. RQ4: Impact of fine-tuning a multi-source model using\nfew-shot samples from the target application\nThis experiment\u2019s objective is to evaluate how well a\nmulti-source model can generalize when adapted using a few\nsamples during the test time. Table VIII shows the %-change in\nMSE when fine-tuning using 1% of samples compared to none.\nWe use Laghos ,Kripke ,miniVite ,SW4lite , and AMG\nto build the source and TESTDFFT as the target application.\nFigure VIII shows that few-shot samples significantly im-\nprove prediction accuracy for some of the models compared to\nno adaptation, meaning the multi-source model can generalize\n4", "mimetype": "text/plain", "start_char_idx": 1548, "end_char_idx": 2971, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7697aa0e-f7e0-49ba-a9fa-f055ba16c5c1": {"__data__": {"id_": "7697aa0e-f7e0-49ba-a9fa-f055ba16c5c1", "embedding": null, "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "65828a06-9dcc-4816-9fe2-c6d04307f32a", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "b8a42df68288c05f86876f39d85af9a2be5beb103f75de967cfd0c2b468d98c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ee5b3b8-eac7-468a-a175-1d60b9b61465", "node_type": "1", "metadata": {}, "hash": "54878f0fb9018a5e2c614c5c792d343b2ffe3c098dbe2df8dd8ef069fb1405ef", "class_name": "RelatedNodeInfo"}}, "text": "TABLE VII: RQ3: Impact of using multiple applications to\nbuild the source model and use it with no adaptation for\nTESTDFFT as the target.\nModel Platforms\nRuby Corona\nARD 1.29E-05 0.01\nADB 5E-03 0.043\nET 1.39E-06 0.047\nBR 4.50E-05 0.002\nSVR 8.48E-06 0.032\nLasso 1.29E-05 0.000\nENet 1.29E-05 0.003\nKNN 4.69E-05 0.031\nDT 1E-05 0.005\nRF 9E-03 0.03\nXGB 5E-07 0.027\nTABLE VIII: RQ4: %-Improvement in MSE of a multi-\nsource model when fine-tuned compared to no adaptation.\nOnly showing the subset of the ML models that shows benefit\nfrom fine-tuning a multi-source model.\nModel Applications\n1%\nRuby Corona\nARD 99.13 99.94\nADB 100.00 99.98\nET 97.17 99.87\nBR 99.88 99.68\nENet 99.52 99.75\nbetter. Specifically, by incorporating just 1% of TESTDFFT\nsamples to fine-tune the ARD model, we observe a remarkable\n99.13% improvement in accuracy for predicting relative per-\nformance on Ruby and a 99.9% improvement for Corona .\nHowever, we only observe this positive result for a subset\nof the ML models, not all. This result necessitates further\ninvestigation using more few-shot samples.\nE. RQ5: Evaluate the predictive models under data scarcity\nThe objective of this experiment is to evaluate the effec-\ntiveness of using an LLM-generated performance samples for\nrelative performance prediction. For Case 2, we assume the\nsource platform to be Quartz , where the new application\u2019s\nhardware performance counter data is available. Additionally,\nwe consider Corona as the target platform and Ruby as\nthe intermediate platform. We consider TESTDFFT as the\ntarget; Laghos andSW4lite are run on Quartz andRuby ;\nKripke andminiVite are run on Ruby andCorona .\nCompared to the single-source Laghos model shown in\nTable V, Table IX shows that the source model built using\ngenerated data from a fine-tuned LLM can actually improve\nthe prediction accuracy. This observation signifies that we\ncan replace the data from Laghos using the generated data,\nreducing the data collection overhead.TABLE IX: RQ5: MSE for TESTDFFT when using an LLM-\ngenerated data for building the source model.\nModels Platforms\nRuby Corona\nARD 0.119 0.092\nADB 0.089 0.028\nET 0.070 0.094\nBR 0.094 0.016\nSVR 0.077 0.027\nRidge 0.045 0.030\nLasso 0.078 0.023\nENet 0.056 0.031\nKNN 0.097 0.243\nRF 0.054 0.087\nXGB 0.075 0.016\nF . Discussions\nIt is evident from Figure 2 that certain applications exhibit\nsimilar behaviors across platforms.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2383, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ee5b3b8-eac7-468a-a175-1d60b9b61465": {"__data__": {"id_": "5ee5b3b8-eac7-468a-a175-1d60b9b61465", "embedding": null, "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "65828a06-9dcc-4816-9fe2-c6d04307f32a", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "b8a42df68288c05f86876f39d85af9a2be5beb103f75de967cfd0c2b468d98c5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7697aa0e-f7e0-49ba-a9fa-f055ba16c5c1", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "78c1cd01836ff565fb15bdc134945b87ef5d67dcff96e98d4b453796987de695", "class_name": "RelatedNodeInfo"}}, "text": "This observation signifies that we\ncan replace the data from Laghos using the generated data,\nreducing the data collection overhead.TABLE IX: RQ5: MSE for TESTDFFT when using an LLM-\ngenerated data for building the source model.\nModels Platforms\nRuby Corona\nARD 0.119 0.092\nADB 0.089 0.028\nET 0.070 0.094\nBR 0.094 0.016\nSVR 0.077 0.027\nRidge 0.045 0.030\nLasso 0.078 0.023\nENet 0.056 0.031\nKNN 0.097 0.243\nRF 0.054 0.087\nXGB 0.075 0.016\nF . Discussions\nIt is evident from Figure 2 that certain applications exhibit\nsimilar behaviors across platforms. This similarity benefits\nmulti-source models, enabling them to perform well in zero-\nshot and few-shot scenarios. Single-source models, on the\nother hand, can suffer from data distribution shifts when ap-\nplications are dissimilar. Moreover, our experiments show that\nfine-tuning an LLM to generate data when training samples are\ninsufficient can be a viable solution approach with the added\nbenefit of reduced data collection overhead.\nV. R ELATED WORKS\nPerformance prediction is a critical task in HPC. Grobelny\net al. [4] propose a scalable framework for HPC perfor-\nmance prediction without incorporating ML methods, whereas\nour approach leverages ML for enhanced accuracy. Nudd et\nal. [11] introduce PACE, a simulation-based framework for\nperformance and execution time prediction, but we use actual\nhardware performance counters for real-time predictions. Car-\nrington et al. [3] propose a framework using signal processing\ntechniques, while our approach employs few-shot learning\nand generative AI for improved accuracy. Ardalani et al. [1]\nuse regression and ensemble models for GPU performance\nprediction from CPU code, focusing on GPU and CPU within\nthe same platform, whereas we predict cross-platform relative\nperformance. Valov et al. [15] explore transferring perfor-\nmance prediction models across hardware platforms but do\nnot address data scarcity, which our approach mitigates by\nusing few-shot samples and existing application data. Lee et\nal. [8] propose polynomial regression and neural networks for\nperformance modeling, whereas we focus on relative perfor-\nmance prediction for new applications using few-shot learning\nand LLMs. Marathe et al. [9] use deep neural networks and\nfew-shot learning for performance prediction, similar to our\napproach, but we further enhance the performance of transfer\nlearning by leveraging LLMs when data is not sufficient. Kim\net al. [7] and Hou et al. [5] utilize log analysis and neural\nnetworks for performance prediction. At the same time, we\nfocus on hardware performance counter data and benchmark\nbasic ML models, reserving advanced techniques for future\nwork. Our method leverages few-shot samples and platform\n5", "mimetype": "text/plain", "start_char_idx": 1834, "end_char_idx": 4560, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d263903d-97d5-411d-a83e-05a3c33133d4": {"__data__": {"id_": "d263903d-97d5-411d-a83e-05a3c33133d4", "embedding": null, "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "53c436961ebd427c697821e9f85d74b0843cac947e108cbfeff122e31957700b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c466e67-ce9d-4a4e-ab96-2c2efde0926f", "node_type": "1", "metadata": {}, "hash": "1503de0ded36b4b7902a9178977d3435257ca07f1eb6fe93ac80e7b6fa1f7f8f", "class_name": "RelatedNodeInfo"}}, "text": "relationships to predict relative performance effectively.\nVI. C ONCLUSIONS\nIn this work, we use a unique HPC dataset collected from\nvarious applications and platforms to evaluate the efficacy of\ntraditional ML models for knowledge transfer. We address two\nscenarios: one with sufficient data and one with insufficient\ndata. Our evaluations show that different types of ML models\nare well-suited for different applications and platforms. when\nample labeled performance samples are available. However,\nwhen data is scarce, using few-shot learning to adapt an LLM\nto fill the data gap can improve the predictive models\u2019 efficacy.\nACKNOWLEDGMENT\nThis work was performed under the auspices of the U.S. De-\npartment of Energy by Lawrence Livermore National Labo-\nratory under Contract DE-AC52-07NA27344 (LLNL-CONF-\n861205). This work was supported in part by LLNL LDRD\nprojects 23-ERD-045 and 24-SI-005.\nREFERENCES\n[1] N. Ardalani, C. Lestourgeon, K. Sankaralingam, and\nX. Zhu. Cross-architecture performance prediction\n(xapp) using cpu code to predict gpu performance. In\nProceedings of the 48th International Symposium on Mi-\ncroarchitecture , MICRO-48, page 725\u2013737, New York,\nNY , USA, 2015. Association for Computing Machinery.\n[2] V . Borisov, K. Sessler, T. Leemann, M. Pawelczyk, and\nG. Kasneci. Language models are realistic tabular data\ngenerators. In The Eleventh International Conference on\nLearning Representations , 2023.\n[3] L. Carrington, A. Snavely, and N. Wolter. A performance\nprediction framework for scientific applications. Future\nGeneration Computer Systems , 22(3):336\u2013346, 2006.\n[4] E. Grobelny, D. Bueno, I. Troxel, A. D. George, and\nJ. S. Vetter. Fase: A framework for scalable performance\nprediction of hpc systems and applications. Simulation ,\n83(10):721\u2013745, 2007.\n[5] Z. Hou, S. Zhao, C. Yin, Y . Wang, J. Gu, and X. Zhou.\nMachine learning based performance analysis and predic-\ntion of jobs on a hpc cluster. In 2019 20th International\nConference on Parallel and Distributed Computing, Ap-\nplications and Technologies (PDCAT) , pages 247\u2013252.\nIEEE, 2019.\n[6] HuggingFace. Distilgpt2.\nhttps://huggingface.co/distilgpt2, 2019.\n[7] S. Kim, A. Sim, K. Wu, S. Byna, Y . Son, and H. Eom.\nTowards hpc i/o performance prediction through large-\nscale log analysis. In Proceedings of the 29th Inter-\nnational Symposium on High-Performance Parallel and\nDistributed Computing , pages 77\u201388, 2020.\n[8] B. C. Lee, D. M. Brooks, B. R. de Supinski, M. Schulz,\nK. Singh, and S. A. McKee. Methods of inferenceand learning for performance modeling of parallel ap-\nplications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2584, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c466e67-ce9d-4a4e-ab96-2c2efde0926f": {"__data__": {"id_": "6c466e67-ce9d-4a4e-ab96-2c2efde0926f", "embedding": null, "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "53c436961ebd427c697821e9f85d74b0843cac947e108cbfeff122e31957700b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d263903d-97d5-411d-a83e-05a3c33133d4", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "ea3e141cd19c7c30d7aec0be6da092a687c0ef47a84b575d1ee858170ccadf40", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c732c7a9-eaa6-453c-ae3c-1ed606da68d7", "node_type": "1", "metadata": {}, "hash": "64984167c04b2a41d4f7a461d09ff2b49b8dba58fb9cabab8b1c1e96a253608a", "class_name": "RelatedNodeInfo"}}, "text": "IEEE, 2019.\n[6] HuggingFace. Distilgpt2.\nhttps://huggingface.co/distilgpt2, 2019.\n[7] S. Kim, A. Sim, K. Wu, S. Byna, Y . Son, and H. Eom.\nTowards hpc i/o performance prediction through large-\nscale log analysis. In Proceedings of the 29th Inter-\nnational Symposium on High-Performance Parallel and\nDistributed Computing , pages 77\u201388, 2020.\n[8] B. C. Lee, D. M. Brooks, B. R. de Supinski, M. Schulz,\nK. Singh, and S. A. McKee. Methods of inferenceand learning for performance modeling of parallel ap-\nplications. In Proceedings of the 12th ACM SIGPLAN\nSymposium on Principles and Practice of Parallel Pro-\ngramming , PPoPP \u201907, page 249\u2013258, New York, NY ,\nUSA, 2007. Association for Computing Machinery.\n[9] A. Marathe, R. Anirudh, N. Jain, A. Bhatele, J. Thi-\nagarajan, B. Kailkhura, J.-S. Yeom, B. Rountree, and\nT. Gamblin. Performance modeling under resource\nconstraints using deep transfer learning. In Proceedings\nof the International Conference for High Performance\nComputing, Networking, Storage and Analysis , SC \u201917,\nNew York, NY , USA, 2017. Association for Computing\nMachinery.\n[10] D. Nichols, A. Movsesyan, J.-S. Yeom, A. Sarkar,\nD. Milroy, T. Patki, and A. Bhatele. Predicting cross-\narchitecture performance of parallel programs. In 37th\nIEEE International Parallel Distributed Processing Sym-\nposium , 2024.\n[11] G. R. Nudd, D. J. Kerbyson, E. Papaefstathiou, S. C.\nPerry, J. S. Harper, and D. V . Wilcox. Pace\u2014a toolset\nfor the performance prediction of parallel and distributed\nsystems. The International Journal of High Performance\nComputing Applications , 14(3):228\u2013251, 2000.\n[12] G. Ozer, S. Garg, N. Davoudi, G. Poerwawinata,\nM. Maiterth, A. Netti, and D. Tafani. Towards a\npredictive energy model for hpc runtime systems using\nsupervised learning. In U. Schwardmann, C. Boehme,\nD. B. Heras, V . Cardellini, E. Jeannot, A. Salis, C. Schi-\nfanella, R. R. Manumachu, D. Schwamborn, L. Ricci,\nO. Sangyoon, T. Gruber, L. Antonelli, and S. L. Scott,\neditors, Euro-Par 2019: Parallel Processing Workshops ,\npages 626\u2013638, Cham, 2020. Springer International Pub-\nlishing.\n[13] L. Shao, F. Zhu, and X. Li. Transfer learning for visual\ncategorization: A survey. IEEE Transactions on Neural\nNetworks and Learning Systems , 26(5):1019\u20131034, 2015.", "mimetype": "text/plain", "start_char_idx": 2071, "end_char_idx": 4331, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c732c7a9-eaa6-453c-ae3c-1ed606da68d7": {"__data__": {"id_": "c732c7a9-eaa6-453c-ae3c-1ed606da68d7", "embedding": null, "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec0be30-36cf-4e97-9b25-8f4842f64eb6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "53c436961ebd427c697821e9f85d74b0843cac947e108cbfeff122e31957700b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c466e67-ce9d-4a4e-ab96-2c2efde0926f", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "ccdda8cdc3d8256dda290bcbd48c1618689cda071d9e099e634671d0c4387649", "class_name": "RelatedNodeInfo"}}, "text": "Towards a\npredictive energy model for hpc runtime systems using\nsupervised learning. In U. Schwardmann, C. Boehme,\nD. B. Heras, V . Cardellini, E. Jeannot, A. Salis, C. Schi-\nfanella, R. R. Manumachu, D. Schwamborn, L. Ricci,\nO. Sangyoon, T. Gruber, L. Antonelli, and S. L. Scott,\neditors, Euro-Par 2019: Parallel Processing Workshops ,\npages 626\u2013638, Cham, 2020. Springer International Pub-\nlishing.\n[13] L. Shao, F. Zhu, and X. Li. Transfer learning for visual\ncategorization: A survey. IEEE Transactions on Neural\nNetworks and Learning Systems , 26(5):1019\u20131034, 2015.\n[14] M. Tanash, B. Dunn, D. Andresen, W. Hsu, H. Yang, and\nA. Okanlawon. Improving hpc system performance by\npredicting job resources via supervised machine learn-\ning. In Proceedings of the Practice and Experience in\nAdvanced Research Computing on Rise of the Machines\n(Learning) , PEARC \u201919, New York, NY , USA, 2019.\nAssociation for Computing Machinery.\n[15] P. Valov, J.-C. Petkovich, J. Guo, S. Fischmeister, and\nK. Czarnecki. Transferring performance prediction mod-\nels across different hardware platforms. ICPE \u201917, page\n39\u201350, New York, NY , USA, 2017. Association for\nComputing Machinery.\n[16] Y . Wang, Q. Yao, J. T. Kwok, and L. M. Ni. Generalizing\nfrom a few examples: A survey on few-shot learning.\nACM Comput. Surv. , 53(3), june 2020.\n6", "mimetype": "text/plain", "start_char_idx": 3760, "end_char_idx": 5084, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "111df506-7ad6-456a-afbc-2735fb3a9a8f": {"__data__": {"id_": "111df506-7ad6-456a-afbc-2735fb3a9a8f", "embedding": null, "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac142b52-8eb9-4888-b5a3-25287bfef816", "node_type": "4", "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "63c0986f11e3f929add0ccc6a5a52b7e72603f4f161ab90c8521aaaaa7fc2382", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d4215fab-1246-4e21-853d-53d3243b1dcf", "node_type": "1", "metadata": {}, "hash": "ec7e5c2571fd56220ddee29728b0c33632a2aed6a894afb3b4fc8dc6c7b2b829", "class_name": "RelatedNodeInfo"}}, "text": "Signal Processing Based Method for Real-Time\nAnomaly Detection in High-Performance\nComputing\nArunavo Dey, Tanzima Islam, Chase Phelps\nDepartment of Computer Science\nTexas State University\nSan Marcos, TX 78666\nhcs77,tanzima,chaseleif@txstate.eduChristopher Kelly\nBrookhaven National Laboratory\nComputer Science Initiative\nLong Island, NY\nckelly@bnl.gov\nAbstract \u2014Performance anomalies can manifest as irregular ex-\necution times or abnormal execution events for many reasons,\nincluding network congestion and resource contention. Detecting\nsuch anomalies in real-time by analyzing the details of perfor-\nmance traces at scale is impractical due to the sheer volume of\ndata High-Performance Computing (HPC) applications produce.\nIn this paper, we propose formulating HPC performance anomaly\ndetection as a signal-processing problem where anomalies can be\ntreated as noise. We evaluate our proposed method in comparison\nwith two other commonly used anomaly detection techniques\nof varying complexity based on their detection accuracy and\nscalability. Since real-time in-situ anomaly detection at a large\nscale requires lightweight methods that can handle a large\nvolume of streaming data, we find that our proposed method\nprovides the best trade-off. We then implement the proposed\nmethod in C HIMBUKO , the first online, distributed, and scalable\nworkflow-level performance trace analysis framework. We also\npropose a novel metric for comparing our proposed signal-\nbased anomaly detection algorithm with two other methods\u2014\na function of accuracy, F1 score, and detection overhead. Our\nexperiments demonstrate that our proposed approach achieves\na 99% improvement for the benchmark datasets and a 93%\nimprovement with C HIMBUKO traces using the proposed metric.\nIndex Terms \u2014Real-time anomaly detection in HPC, Signal based\nanomaly detection, Fast Fourier Transform, C HIMBUKO .\nI. I NTRODUCTION\nMany modern HPC applications are comprised of tightly-\ncoupled components which execute concurrently, exchange\ninformation, and compete for hardware resources [6]. Con-\ntention for shared resources such as compute, memory, I/O,\nand network resources can introduce a large fluctuation in\nperformance, otherwise known as performance anomalies. De-\ntection of performance anomalies can aid in better utilization\nof resources, improving the performance of applications, and\nreducing the cost of running large-scale applications.\nDue to complexities in communication patterns and resource\ncontention, assessing performance and identifying possible\nbottlenecks in large-scale jobs requires tools capable of cap-\nturing these interactions while avoiding impacting application\nperformance. C HIMBUKO [11] is the first online, distributed,and scalable workflow-level performance trace analysis frame-\nwork that detects performance anomalies in function ex-\necution time at scale. However, anomalous behavior can\nalso manifest outside of execution time. For instance, an\nanomaly that may also affect the under-utilization of a system\nis a considerable variation in the number of instructions\nacross ranks. Anomalies such as this appear in the number\nof instructions and are captured by a hardware performance\ncounter. Extending C HIMBUKO \u2019s existing capability to include\nan analysis of performance counters can be challenging. It\nrequires re-designing the framework\u2019s data structures to hold\nmore information while maintaining a small memory footprint.\nCurrently, C HIMBUKO uses the Histogram-based Outlier Score\n(HBOS) algorithm [8] to detect anomalies in function exe-\ncution time with a server-client execution model where the\nserver and the clients periodically synchronize.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3663, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4215fab-1246-4e21-853d-53d3243b1dcf": {"__data__": {"id_": "d4215fab-1246-4e21-853d-53d3243b1dcf", "embedding": null, "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac142b52-8eb9-4888-b5a3-25287bfef816", "node_type": "4", "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "63c0986f11e3f929add0ccc6a5a52b7e72603f4f161ab90c8521aaaaa7fc2382", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "111df506-7ad6-456a-afbc-2735fb3a9a8f", "node_type": "1", "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "b6bc58dc7245c6c1ef33e5d7f99275e755a3530ec460c8610639f05fa38e2426", "class_name": "RelatedNodeInfo"}}, "text": "However, anomalous behavior can\nalso manifest outside of execution time. For instance, an\nanomaly that may also affect the under-utilization of a system\nis a considerable variation in the number of instructions\nacross ranks. Anomalies such as this appear in the number\nof instructions and are captured by a hardware performance\ncounter. Extending C HIMBUKO \u2019s existing capability to include\nan analysis of performance counters can be challenging. It\nrequires re-designing the framework\u2019s data structures to hold\nmore information while maintaining a small memory footprint.\nCurrently, C HIMBUKO uses the Histogram-based Outlier Score\n(HBOS) algorithm [8] to detect anomalies in function exe-\ncution time with a server-client execution model where the\nserver and the clients periodically synchronize. HBOS creates\nhistogram bins to reflect statistically normal accumulated func-\ntion execution times. A challenge in extending HBOS to detect\nanomalies in an arbitrary number of counters is that hundreds\nof bins could be generated per counter, where each bin needs\nto be described using several parameters. The algorithm\u2019s\nparameters, information needed to duplicate histograms of\nall counters, is synchronized between the server and client\ncomponents via the network. Using HBOS for hundreds of\ncounters could easily create bottlenecks in memory usage and\nnetwork traffic as the number of monitored counters increases.\nTo address this challenge, we propose a new method for\nhandling a large volume of performance counter information\narriving in real-time and detecting anomalies in their values.\nSpecifically, we propose formulation of performance anomaly\ndetection in HPC as a noise detection problem akin to that in\nthe area of signal processing. This novel formulation enables\nleveraging the principled approach of noise detection us-\ning Fast Fourier Transform (FFT)-based signal decomposition.\nIn a real-time analysis framework, the large volume of counter\nvalues can quickly accumulate to an unmanageable size. To\nreduce the memory footprint of client processes and the\n1", "mimetype": "text/plain", "start_char_idx": 2865, "end_char_idx": 4940, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4cbcc6cb-a133-4f99-8840-4fab42e312eb": {"__data__": {"id_": "4cbcc6cb-a133-4f99-8840-4fab42e312eb", "embedding": null, "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a", "node_type": "4", "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "94f19d830c8d9b7d45b37c64f91c295ea876a768d44b7c82c06a2bcb7ec1acb7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57a9ea42-5b75-4bcc-9244-688421dd01b6", "node_type": "1", "metadata": {}, "hash": "312c9776228ad87bffdb203cc07b4a104d8c647b68dc6ccfe550b5c42fb004df", "class_name": "RelatedNodeInfo"}}, "text": "volume of data transferred to the server, each client aggregates\ncounter values. In contrast, the server uses statistical metrics\nto build a signal across ranks as a secondary metric. Clients\nuse these secondary metrics to label individual counters as\nanomalous if they are beyond a configurable range.\nWe compare our proposed approach with two other algorithms\nof varying complexity from statistical analysis and Machine\nLearning (ML) domains. Since real-time anomaly detection\nrequires methods to be fast and accurate, we propose a new\nmetric to evaluate algorithms to assess their suitability in real-\ntime performance anomaly detection scenarios. Specifically,\nthe metric calculates the trade-off between algorithmic perfor-\nmance and the overhead introduced usingaccuracy \u00d7F1score\noverhead,\nwhere a higher value indicates more algorithmic performance\nin less time, and that an algorithm is more suitable for real-\ntime use.\nIn summary, the main contributions of this paper are:\n\u2022Formulating performance anomaly detection as a signal\nprocessing problem to use FFT to identify anomalies.\n\u2022Proposing a novel metric for comparing the applicability\nof anomaly detection techniques in real-time performance\nmonitoring frameworks.\n\u2022A comparison of the proposed approach with different\nalgorithms using benchmark applications and trace data\nfrom a scientific application for anomaly detection based\non the proposed metric.\n\u2022We demonstrate that our proposed approach provides the\nbest trade-off between accuracy and F1 score, ideal for\nreal-time anomaly detection.\nIn this paper, we compare our proposed FFT-based approach\nwith Auto Regressive Integrated Moving Average (ARIMA)\nand Robust Random Cut Forest (RRCF). ARIMA [22] is a\nwidely used statistical method, whereas RRCF [9] is a more\nrecent ML based anomaly detection technique. Our thorough\nevaluations show that the accuracy \u00d7F1score of the FFT-\nbased method on six benchmark applications offers as much as\n99.1% improvement compared to ARIMA, 99.4% compared\nto RRCF, and, for performance traces from C HIMBUKO , an\nimprovement of up to 90% compared to ARIMA and 95%\nwith RRCF.\nThe rest of this paper is organized as follows: in Section II,\nwe describe the C HIMBUKO framework, the HBOS algo-\nrithm, currently implemented by C HIMBUKO , and the ARIMA\nand RRCF algorithms; Section III describes our proposed\napproach of a signal processing-based method for perfor-\nmance anomaly detection; Section V describes the experi-\nmental setup; Section VI describes the evaluation results; we\npresent related work in Section VII; we conclude the paper in\nSection VIII.\nFig. 1: Overview of C HIMBUKO\nII. B ACKGROUND\nA.CHIMBUKO framework\nFigure 1 provides an overview of the C HIMBUKO framework.\nThe C HIMBUKO framework provides functionality through\nthree components: Anomaly Detection Component (AD), Pa-\nrameter Server Component (PS), and Provenance Database\n(ProvDB). The AD component consists of a single process\nper node which runs alongside the application processes of\na workflow. The nodes running an AD instance and work-\nflow processes are called \u201cbody nodes\u201d. Each AD instance\nreceives performance data from Tuning and Analysis Utilities\n(TAU) [1] and determines if a function is anomalous by\napplying the HBOS algorithm to the function\u2019s execution time.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3308, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "57a9ea42-5b75-4bcc-9244-688421dd01b6": {"__data__": {"id_": "57a9ea42-5b75-4bcc-9244-688421dd01b6", "embedding": null, "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a", "node_type": "4", "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "94f19d830c8d9b7d45b37c64f91c295ea876a768d44b7c82c06a2bcb7ec1acb7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cbcc6cb-a133-4f99-8840-4fab42e312eb", "node_type": "1", "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "8b2f78bca0622ce4d122cb09c2d442143cfe9b1b73833c3b2bbca1a36a59a0bb", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 1: Overview of C HIMBUKO\nII. B ACKGROUND\nA.CHIMBUKO framework\nFigure 1 provides an overview of the C HIMBUKO framework.\nThe C HIMBUKO framework provides functionality through\nthree components: Anomaly Detection Component (AD), Pa-\nrameter Server Component (PS), and Provenance Database\n(ProvDB). The AD component consists of a single process\nper node which runs alongside the application processes of\na workflow. The nodes running an AD instance and work-\nflow processes are called \u201cbody nodes\u201d. Each AD instance\nreceives performance data from Tuning and Analysis Utilities\n(TAU) [1] and determines if a function is anomalous by\napplying the HBOS algorithm to the function\u2019s execution time.\nThe PS and the ProvDB components each run as a single\nmulti-threaded process and are typically run on the \u201chead-\nnode\u201d, separate from the body nodes. The ProvDB records\nanomaly provenance information and the PS coordinates syn-\nchronization of calculated runtime statistics among all AD\ninstances.\nB. HBOS algorithm\nEach AD component creates a histogram of the elapsed run\ntime for all executions of each function. The PS component\naggregates each client\u2019s histogram for each function, adjusting\nthe number of bins and bin widths as necessary, and returns\nan aggregated histogram for each function to each AD com-\nponent. The HBOS algorithm has configurable parameters,\nincluding the hbos threshold to control the algorithm\u2019s sensi-\ntivity, and the maximum number of bins of a histogram which\naffects the algorithm\u2019s tolerance to variance.\nAdditionally, to provide information to provenance, the C HIM-\nBUKO framework records information of each histogram in-\ncluding the location of bin edges, widths, and the count of\nvalues within each bin. For each function, the AD calcu-\nlates a score for each bin within the function\u2019s histogram\nusing the equation: score =\u22121\u2217lg(contribution +\u03b1),\nwhere contribution is the number of values within the\nbin divided by the number of values within the histogram,\nand\u03b1is defined as a near-zero value, a floating-point ep-\nsilon. The parameter hbos threshold , set to 0.99, is used\nto calculate lthreshold using the equation lthreshold =\nmin score +(hbos threshold \u2217(max score\u2212min score )),\n2", "mimetype": "text/plain", "start_char_idx": 2613, "end_char_idx": 4835, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b17472d-dc4b-46c8-8e97-61feb135c6db": {"__data__": {"id_": "6b17472d-dc4b-46c8-8e97-61feb135c6db", "embedding": null, "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c325e890-cc06-41dc-bb94-176cace6b10a", "node_type": "4", "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "b44e90a62c0a71304512f1d55245086c45510a78d0081fa4b2d67dc1267b2a18", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d932e14b-f4a5-47c2-b590-5f5b2efe89b3", "node_type": "1", "metadata": {}, "hash": "0c7c827ac5a645c280b8d4fa60f8a89e22d2194ccd1f519faf6ebcee3526c9c5", "class_name": "RelatedNodeInfo"}}, "text": "where min score andmax score are, respectively, the min-\nimum and maximum of bin scores.\nHBOS determines a function to be anomalous if it contains\nan event whose run time is beyond the edges of the function\u2019s\nouter left- or right-most histogram bins by more than 5%of\nthe width of the bins of the histogram, or if the function\u2019s his-\ntogram contains a bin whose score is greater than lthreshold .\nC. ARIMA\nARIMA is a regression-based ML model [22], [5], that pre-\ndicts the current observation using previous observations. If\nthe current observation Ytdepends on the past observations\nYt\u22121, Yt\u22122, ..., then ARIMA predicts the expected value of\nthe current observation Ytusing Equation 1:\nYt= (\u03b21+\u03b22) + (\u03d51Yt\u22121+\u03d52Yt\u22122+...+\u03d5pYt\u2212p)\n+ (\u03c91\u03f5t\u22121+\u03c92\u03f5t\u22122+...+\u03c9p\u03f5t\u2212q)(1)\nIn this equation, \u03b21and\u03b22are constants, pis the number of\nlagged observations included in the calculation, and qis the\nsize of the moving window. The \u201cI\u201d in ARIMA stands for\n\u201cIntegrated\u201d, highlighting that ARIMA uses the differences in\nthe observations for predictions.\nD. Robust Random Cut Forest (RRCF)\nRRCF [9] is a tree-based ensemble method that is designed\nto handle high-dimensional streaming data. In RRCF, perfor-\nmance counter values at each timestep are inserted as nodes in\na tree. Each node of the tree has a bit depth equal to the number\nof bits needed to store the value. The model\u2019s complexity is\nthe sum of the bit depths of all nodes already inserted. The\nexpected change in complexity, or displacement, caused by the\ninsertion of node xis quantified by Equation 2, where xis\nthe newly inserted node, Zis the set of all other nodes, Tis\nthe RRCF tree, and f(y, Z, T )represents the depth of yinT\ndefined by all other nodes in Z. The term on the right-hand\nside denotes the expected change in the bit depths of all leaves\nin the tree when x is inserted.\nDisp (x, Z) =X\nT,y\u2208Z\u2212xPr[T](f(y, Z, T )\u2212f(y, Z\u2212x, T))\n(2)\nA new value is considered an outlier if the insertion of that\nvalue significantly increases the complexity of the model as a\nnew node in the tree.\nRRCF calculates the displacement xby forming \u201ccollusive\ndisplacement\u201d, where a set of colluders, C, along with the\npoint of interest, x, are removed. Cis the set of duplicates\nand near duplicates that could mask the presence of outliers.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2274, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d932e14b-f4a5-47c2-b590-5f5b2efe89b3": {"__data__": {"id_": "d932e14b-f4a5-47c2-b590-5f5b2efe89b3", "embedding": null, "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c325e890-cc06-41dc-bb94-176cace6b10a", "node_type": "4", "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "b44e90a62c0a71304512f1d55245086c45510a78d0081fa4b2d67dc1267b2a18", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b17472d-dc4b-46c8-8e97-61feb135c6db", "node_type": "1", "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "36138714926f84843a673a8cfd9d56841095e900426bc0e11a59f1462ba2268c", "class_name": "RelatedNodeInfo"}}, "text": "Disp (x, Z) =X\nT,y\u2208Z\u2212xPr[T](f(y, Z, T )\u2212f(y, Z\u2212x, T))\n(2)\nA new value is considered an outlier if the insertion of that\nvalue significantly increases the complexity of the model as a\nnew node in the tree.\nRRCF calculates the displacement xby forming \u201ccollusive\ndisplacement\u201d, where a set of colluders, C, along with the\npoint of interest, x, are removed. Cis the set of duplicates\nand near duplicates that could mask the presence of outliers.\nEquation 3 describes the calculation of collusive displacement:\nCoDisp (x, Z,|S|) = E\nS\u2286Z,T[max\nx\u2208C\u2286S1\n|C|X\ny\u2208S\u2212C(f(y, S, T )\n\u2212f(y, S\u2212C, T\u2032\u2032))] (3)\n0.0 0.2 0.4 0.6 0.8 1.0\nTime (s)4\n2\n024Amplitude(a) Continuous signal\n0 2 4 6 8 10\nFreq (Hz)050010001500200025003000FFT Amplitude |X(freq)|\n(b) Transformed discrete signal from FFT\nFig. 2: FFT transformation of a Continuous Signal\nIII. O URAPPROACH\nA. Signal Processing based Anomaly Detection\nWith inspiration from signal processing, we formulate the\nproblem of performance anomaly detection similar to noise\ndetection in analog signals. To consider performance analysis\nas noise detection, we form a signal by concatenating counter\nvalues per function across ranks for all call paths over each\ntime step as a vector. Similar to signal processing, we then\napply the FFT method to obtain frequency and amplitude com-\nponents from continuous counter signals. Figure 2 illustrates\nthis transformation, where the continuous signal in Figure 2(a)\nis discretized as shown in Figure 2(b). An anomalous counter\nvalue is either a large or small amplitude value whose change\nin variance compared to previous timesteps is greater than a\nthreshold. The rationale for using a method such as FFT is\nthat values from continuous variables, such as execution time\nacross ranks and timesteps can be transformed into a discrete\nform. Such discretization eliminates the need for calculating\nhistogram bin widths, which can be ad-hoc in the HBOS\nalgorithm. We aggregate counter values for several timesteps\nby averaging them to create a continuous signal before we\ncheck for performance anomalies.\nEach workflow process applies FFT to a series of counter\nvalues and, using the real parts of the signal, calculates their\n3", "mimetype": "text/plain", "start_char_idx": 1832, "end_char_idx": 4024, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8921507e-616c-4489-b81c-f7b24ff0031a": {"__data__": {"id_": "8921507e-616c-4489-b81c-f7b24ff0031a", "embedding": null, "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8e35081f-bd3c-4909-a3a0-8c2c7e327df1", "node_type": "4", "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "bb71be7b1d1930edc60218c61b015fbb7009ec948d487349e3ec5565054c2a0e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97398f38-f881-4e86-a3a9-1f62e0bc5bdc", "node_type": "1", "metadata": {}, "hash": "9ce06ee4f0b3af0630e62c0371a30da0c71c91d4eaedffe6181818c5540a45c7", "class_name": "RelatedNodeInfo"}}, "text": "mean using Equation 4.\n\u00b5=nX\ni=1[xi/n] (4)\nLikewise, the variance of the real values is calculated by\nEquation 5.\n\u03c32=nX\ni=1[(xi\u2212\u00b5)2/n] (5)\nIf there are no historical statistics for a counter, we set the\nhistorical mean, \u00b5h=\u00b5, the historical variance, \u03c32\nh=\u03c32,\nthe historical difference, diff h= 0, and do not mark the\ncounter as anomalous.\nWe use the parameters: threshold = 3,\u03b1= 0.8,\u03b2= 42 ,\nand\u03b3= 0.3. When historical statistics exist, we calculate\nthe change in variance as \u03b4=|\u03c32\nh\u2212\u03c32|/\u03c32\nh, and, if not\n\u03b4 > threshold , we mark the counter as anomalous and assign\n\u03b4= (\u03b3\u2217\u03b4) + ((1 \u2212\u03b3)\u2217\u03b4h). We then assign \u03b4h=\u03b4and\n\u00b5h= (\u03b1\u2217\u00b5h)+((1\u2212\u03b1)\u2217\u00b5). Concluding the evaluation of each\ncounter, we set \u03c32\nh= (\u03b2\u2217\u03c32)+((1\u2212\u03b2)\u2217\u03c32\nh)if we had marked\nthe counter as anomalous, or \u03c32\nh= (\u03b1\u2217\u03c32) + ((1 \u2212\u03b1)\u2217\u03c32\nh)\notherwise.\nIV. I NTEGRATION WITH CHIMBUKO\nTo integrate our proposed anomaly detection algorithms for\ncounter-wise and rank-wise anomaly detection in C HIMBUKO ,\nwe extend both the AD and PS components described in\nSection II. Each AD component receives lists of execution\ndata, where execution data includes function names, call paths,\nunique function IDs, event entry and exit timestamps, and all\ncounter values collected during the execution of each function.\nEach AD component determines functions to be anomalous\naccording to the chosen anomaly detection algorithm which is\nresponsible for analysis of the incoming stream of execution\ndata. The AD component sends provenance information of\nanomalous events, including the rank ID and function descrip-\ntion, to the ProvDB component.\nFor each additional algorithm in this work, we design a map\nof values keyed according to unique call path and counter in\nthe AD component. During synchronization, AD components\nsend these data structures to the PS component which then\nmerges these values and returns the merged structure to each\nAD.\nIn the FFT algorithm, each AD additionally appends counter\nvalues to a list during iteration of the execution data. Following\niteration of events in each function, if we have a minimum\nnumber of values for a counter, we perform the FFT algorithm\nand determine whether a counter is anomalous as described\nin Section III, clear the counter value list, and update our\nhistorical statistics. Historical statistics of each PS are merged\nusing the minimum of all AD statistics.V. E XPERIMENTAL SETUP\nIn this section, we describe the setup of experiments and\nmetrics we use to evaluate the accuracy of the proposed\nanomaly detection algorithms using trace data of the NWChem\napplication collected by the C HIMBUKO framework. To eval-\nuate the performance of each algorithm, we augment the trace\ndata with manually injected anomalies. We run C HIMBUKO\nto replay the trace of NWChem for each new algorithm and\nuse a pseudo-random number generator with a fixed seed to\ngenerate artificial counter values to be treated as anomalies.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2892, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97398f38-f881-4e86-a3a9-1f62e0bc5bdc": {"__data__": {"id_": "97398f38-f881-4e86-a3a9-1f62e0bc5bdc", "embedding": null, "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8e35081f-bd3c-4909-a3a0-8c2c7e327df1", "node_type": "4", "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "bb71be7b1d1930edc60218c61b015fbb7009ec948d487349e3ec5565054c2a0e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8921507e-616c-4489-b81c-f7b24ff0031a", "node_type": "1", "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "3f88f43a3dc7ea0761b55aecfa719401cd4d18e9d5a4074a4504a173e3c89934", "class_name": "RelatedNodeInfo"}}, "text": "Following\niteration of events in each function, if we have a minimum\nnumber of values for a counter, we perform the FFT algorithm\nand determine whether a counter is anomalous as described\nin Section III, clear the counter value list, and update our\nhistorical statistics. Historical statistics of each PS are merged\nusing the minimum of all AD statistics.V. E XPERIMENTAL SETUP\nIn this section, we describe the setup of experiments and\nmetrics we use to evaluate the accuracy of the proposed\nanomaly detection algorithms using trace data of the NWChem\napplication collected by the C HIMBUKO framework. To eval-\nuate the performance of each algorithm, we augment the trace\ndata with manually injected anomalies. We run C HIMBUKO\nto replay the trace of NWChem for each new algorithm and\nuse a pseudo-random number generator with a fixed seed to\ngenerate artificial counter values to be treated as anomalies.\nDuring each time step, if the distance between the generated\nartificial value and the mean is greater than \u03c3\u00d7standard\ndeviations, then it is inserted as an anomalous value. The total\nnumber and position of injected anomalies are chosen using\nthe pseudo-random number generator.\nA. Applications:\nNWChem: NWchem is a high-performance computational\nchemistry tool that provides quantum chemical and molecular\ndynamics functionality. It is designed to run on HPC systems,\nworkstations, and clusters, and scales both in terms of problem\nsize and resource usage.\nNumenta Anomaly Benchmark (NAB): The Numenta\nAnomaly Benchmark (NAB) [14] dataset is a corpus of 58\nreal-time series data. This benchmark contains both real-world\nand artificially generated data. We list below the datasets we\nuse for evaluation along with a brief description of each:\nTwitter: A collection of real-world Twitter data where each\nvalue represents the number of mentions of large publicly-\ntraded companies every 5 minutes.\nTemperature: Ambient temperature data from an office.\nAdexchange: Rate of clicks for online advertisements.\nEC2 utilization: CPU usage data collected as AWS server\nmetrics by the AmazonCloudwatch service.\nCPU utilization: Average CPU usage data from Amazon Web\nServices from a cluster.\nSedov: A Sedov solver simulation from the FLASH applica-\ntion.\nB. Evaluation Metrics:\nTable I summarizes the metrics that we use for performance\nevaluation. In addition to the metrics listed in Table I, we\nuse our proposed metric (accuracy \u00d7F1score )/overhead\nto compare each algorithm.\nVI. R ESULTS\nIn this section, we compare the effectiveness of our proposed\nFFT-based method, ARIMA, and RRCF methods in anomaly\ndetection of the applications described in Section V. Specifi-\ncally, we investigate the:\n\u2022Overhead of FFT, ARIMA, and RRCF with each appli-\ncation and dataset.\n\u2022Performance of each algorithm using our proposed metric\n4", "mimetype": "text/plain", "start_char_idx": 1987, "end_char_idx": 4808, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c0ad5c5-cb17-4ab3-a3b0-3f7661e62d6e": {"__data__": {"id_": "7c0ad5c5-cb17-4ab3-a3b0-3f7661e62d6e", "embedding": null, "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c901dae-b4d8-461f-b233-aa9dbe34ca9c", "node_type": "4", "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "1bc2de3cdadaa1a571984fbb492c6734dba819a39f349d3621207be9fd21af99", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc8d3c3a-8ae9-4bb3-a8f9-9d8be58b074d", "node_type": "1", "metadata": {}, "hash": "2b993e8905040a2b2ff6ff53d876760767a2c4151e84f369cca681e73e037841", "class_name": "RelatedNodeInfo"}}, "text": "TABLE I: Evaluation Metrics\nEvaluation Metrics\nMetric Meaning Equation\nPrecision Fraction of correctly labeled anomaliesTruePositive\nTruePositive +FalsePositive\nRecall Fraction of anomalies reported compared to total injected anomaliesTruePositive\nTruePositive +FalseNegative\nAccuracy Fraction of true anomalies from true predictionsTruePositive\nTruePositive +TrueNegative\nF1 Score Harmonic mean of precision and recallTruePositive\nTruePositive +0.5(FalsePositive +FalseNegative )\nOverhead The log of seconds spent in an anomaly detection algorithm\nTwitter\nTemperature\nEC2_utilizationAd exchangeCpu_utilizationSedov00.20.40.60.81\nFFT ARIMA RRCF\nDatasetAccuracy\nFig. 3: Comparison of Accuracy\naccuracy \u00d7F1score\noverhead.\n\u2022Robustness of each algorithm in terms of performance\nand overhead.\nA. Experiment with benchmark datasets\nIn this experiment, we evaluate the performance of FFT,\nARIMA, and RRCF using 6 benchmark datasets of real-time\nseries data.\nFigure 3 shows the accuracy of the algorithms FFT, ARIMA,\nand RRCF with the benchmark datasets. We see algorithms\nperform similar with the NAB real-time datasets, except\nSedov, where FFT performs better than ARIMA and RRCF.\nEvaluating accuracy alone isn\u2019t sufficient to select a real-time\nanomaly detection algorithm, the rate of false positive and\nfalse negative predictions also plays a crucial role. Thus, the\nF1 score, being a combination of these, is a useful metric\nto consider. Figure 4 shows the calculated F1 score of each\nalgorithm in this experiment. Viewing the F1 score in the\nfigure, we can clearly see FFT outperforms ARIMA and\nRRCF. Aside from the Sedov dataset, ARIMA and RRCF\nsuffer either poor recall or poor precision resulting in a\nnegligible F1 score. Across algorithms for each dataset, we\nnote similar error margins of F1 scores.\nWe combine the F1 score and the accuracy to obtain the\n\u201carea\u201d, where area =F1\u00d7accuracy . We determine which\nalgorithm will give us the best trade-off between the area\nand overhead by dividing the area by the overhead of each\nalgorithm. Figure 5 depicts the ratio of area to overhead of\neach algorithm with the benchmark datasets. As the datasets\nTwitter\nTemperature\nEC2_utilizationAd exchangeCpu_utilizationSedov00.20.40.60.81\nFFT ARIMA RRCF\nDatasetF1Fig. 4: Comparison of F1 Score\nhave already been collected, overheads are smaller. In spite of\nthis, ARIMA and RRCF have a higher overhead in comparison\nto FFT because of the complexity of data structures used. Both\nthe higher overhead and lower F1 score contributes to the low\narea/overhead score of ARIMA and RRCF.\nTwitter\nTemperature\nEC2_utilizationAd exchangeCpu_utilizationSedov00.20.40.60.81 FFT ARIMA RRCF\nDatasetArea/Overhead\nFig. 5: Comparison of Area/Overhead\nTable II provides a summary of the best performing algorithm\nfor each metric with each of the datasets used.\nB. Experiment with CHIMBUKO\nIn this experiment, we define \u03b1as the granularity of errors, and\n\u03c3, as the sensitivity of each algorithm, and we randomly insert\nanomalous data across the 1000 timesteps of the application\u2019s\nrun.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3058, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc8d3c3a-8ae9-4bb3-a8f9-9d8be58b074d": {"__data__": {"id_": "bc8d3c3a-8ae9-4bb3-a8f9-9d8be58b074d", "embedding": null, "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c901dae-b4d8-461f-b233-aa9dbe34ca9c", "node_type": "4", "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "1bc2de3cdadaa1a571984fbb492c6734dba819a39f349d3621207be9fd21af99", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c0ad5c5-cb17-4ab3-a3b0-3f7661e62d6e", "node_type": "1", "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "c194aaa4ec685886d1745f5b316ca11f4d7f0a3995e65df3e84ef25cf87631a3", "class_name": "RelatedNodeInfo"}}, "text": "In spite of\nthis, ARIMA and RRCF have a higher overhead in comparison\nto FFT because of the complexity of data structures used. Both\nthe higher overhead and lower F1 score contributes to the low\narea/overhead score of ARIMA and RRCF.\nTwitter\nTemperature\nEC2_utilizationAd exchangeCpu_utilizationSedov00.20.40.60.81 FFT ARIMA RRCF\nDatasetArea/Overhead\nFig. 5: Comparison of Area/Overhead\nTable II provides a summary of the best performing algorithm\nfor each metric with each of the datasets used.\nB. Experiment with CHIMBUKO\nIn this experiment, we define \u03b1as the granularity of errors, and\n\u03c3, as the sensitivity of each algorithm, and we randomly insert\nanomalous data across the 1000 timesteps of the application\u2019s\nrun. While varying \u03b1and\u03c3, we measure the accuracy of each\nalgorithm with real-time C HIMBUKO data. In Figure 6, the y-\naxis shows the average accuracy of each algorithm, each bar\n5", "mimetype": "text/plain", "start_char_idx": 2339, "end_char_idx": 3234, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad3c2cc7-4123-4c4c-95db-6e845fb67d31": {"__data__": {"id_": "ad3c2cc7-4123-4c4c-95db-6e845fb67d31", "embedding": null, "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c12de919-96a7-44bc-9d9a-0cc878ae3018", "node_type": "4", "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "3f40b49dc0100dadde0bc593221bf9e41737fed09ba68d04dc903492b5505fd8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "43800959-3c1f-4625-8777-69e204f92dba", "node_type": "1", "metadata": {}, "hash": "ebc4665738761e508c7c81634d2ccf79a7b80570bc45c39c3a501af0224b0dfd", "class_name": "RelatedNodeInfo"}}, "text": "TABLE II: Summary Evaluation\nMetrics\nData set Metric Best Performing Algorithm Value\nTwitterAccuracy ARIMA 0.53\u00b10.013\nF1 FFT 0.47\u00b10.013\nOverhead FFT 0.43\u00b11.3\nTemperatureAccuracy RRCF 0.55\u00b10.005\nF1 FFT 0.45\u00b10.018\nOverhead FFT 0.5\u00b11.28\nEC2\u02d9utilizationAccuracy ARIMA 0.52\u00b10.012\nF1 FFT 0.482\u00b10.012\nOverhead FFT 0.53\u00b11.5\nAd Exchange Accuracy ARIMA 0.57\u00b10.013\nF1 FFT 0.51\u00b10.039\nOverhead FFT 0.53\u00b10.96\nCPU Utilization Accuracy ARIMA 0.52\u00b10.01\nF1 FFT 0.48\u00b10.01\nOverhead FFT 0.5\u00b11.2\nSedovAccuracy FFT 0.95\u00b10.05\nF1 FFT 0.7\u00b10.15\nOverhead FFT 0.77\u00b10.5\n1 2 300.20.40.60.81FFT Sigma 1 ARIMA Sigma 1 RRCF Sigma 1\nFFT Sigma 2 ARIMA Sigma 2 RRCF Sigma 2\nFFT Sigma 3 ARIMA Sigma 3 RRCF Sigma 3\nAlphaAccuracy\nFig. 6: Accuracy for \u03c3= 1\u21923,\u03b1= 1\u21923\nrepresents an algorithm and \u03c3value, and bars are grouped\nwith the value of \u03b1increasing along the x-axis.\nIn figure 6, we note RRCF has a very low accuracy for\ndetection of errors with small granularity, when \u03b1= 1, where\nFFT and ARIMA both have an accuracy greater than 0.8. We\nalso note that for every \u03b1FFT and ARIMA have a similar\naccuracy. Figure 7 shows the corresponding F1 scores for this\nexperiment, here we see that, as compared with the benchmark\ndatasets experiment, all algorithms have an increased F1 score,\nthough FFT still clearly outperforms both ARIMA and RRCF.\nMoreover, in all experiments, we note that the overhead of\nFFT is significantly lower than that of ARIMA and RRCF.\nFigure 8 shows the overhead during the first 100 timesteps\nfor each algorithm with \u03c3= 1 and\u03b1varied between 1 and\n3. The timestep is represented along the x-axis and the y-axis\nrepresents the overhead as the log value of the time taken by\neach respective algorithm. The value of \u03b1is shown in the\nlegend, preceded by the name of the algorithm. Initially, for a\nsmall number of timesteps, FFT has a higher overhead due to\nsetup costs as it begins. The overhead of FFT quickly drops\n1 2 300.20.40.60.81\nFFT Sigma 1 ARIMA Sigma 1 RRCF Sigma 1\nFFT Sigma 2 ARIMA Sigma 2 RRCF Sigma 2\nFFT Sigma 3 ARIMA Sigma 3 RRCF Sigma 3\nAlphaF1Fig. 7: F1 Score for \u03c3= 1\u21923,\u03b1= 1\u21923\nFig. 8: Overhead for \u03c3= 1,\u03b1= 1\u21923\nand becomes stable, with an overall overhead lower than that\nof ARIMA and RRCF.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2187, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "43800959-3c1f-4625-8777-69e204f92dba": {"__data__": {"id_": "43800959-3c1f-4625-8777-69e204f92dba", "embedding": null, "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c12de919-96a7-44bc-9d9a-0cc878ae3018", "node_type": "4", "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "3f40b49dc0100dadde0bc593221bf9e41737fed09ba68d04dc903492b5505fd8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad3c2cc7-4123-4c4c-95db-6e845fb67d31", "node_type": "1", "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "9d053f79892211dc0fca67912b04244f28773ad26b9f1b3e575d686627cade4c", "class_name": "RelatedNodeInfo"}}, "text": "The value of \u03b1is shown in the\nlegend, preceded by the name of the algorithm. Initially, for a\nsmall number of timesteps, FFT has a higher overhead due to\nsetup costs as it begins. The overhead of FFT quickly drops\n1 2 300.20.40.60.81\nFFT Sigma 1 ARIMA Sigma 1 RRCF Sigma 1\nFFT Sigma 2 ARIMA Sigma 2 RRCF Sigma 2\nFFT Sigma 3 ARIMA Sigma 3 RRCF Sigma 3\nAlphaF1Fig. 7: F1 Score for \u03c3= 1\u21923,\u03b1= 1\u21923\nFig. 8: Overhead for \u03c3= 1,\u03b1= 1\u21923\nand becomes stable, with an overall overhead lower than that\nof ARIMA and RRCF.\nFigure 9 shows the area/overhead of each algorithm as\nwe vary both \u03c3and\u03b1. It is important to note that the\narea/overhead of FFT is greater than one due to an average\noverhead of less than 1. We see that as \u03b1increases, algorithms\nperform better as the granularity of the errors grows which\n6", "mimetype": "text/plain", "start_char_idx": 1682, "end_char_idx": 2478, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e018cb5-4924-430b-a91a-d194015eb6a9": {"__data__": {"id_": "2e018cb5-4924-430b-a91a-d194015eb6a9", "embedding": null, "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3183f3-76e1-4826-a144-f839e72a2072", "node_type": "4", "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "e651456fb488c659dd20369f930a3707598369e928a4ecf89738f95203ae362b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad192068-9a0a-45d0-b8bd-9f24df73b9d3", "node_type": "1", "metadata": {}, "hash": "a0539d796aa376416aeccc27cd79fbbe81c16dcab73243baa6bf98b687463de0", "class_name": "RelatedNodeInfo"}}, "text": "1 2 300.20.40.60.811.21.4FFT Sigma 1 ARIMA Sigma 1 RRCF Sigma 1\nFFT Sigma 2 ARIMA Sigma 2 RRCF Sigma 2\nFFT Sigma 3 ARIMA Sigma 3 RRCF Sigma 3\nAlphaArea/OverheadFig. 9: Area /Overhead for Sigma, \u03c3= 1\u21923, Alpha, \u03b1=\n1\u21923\nleads to a decrease in the numbers of errors. FFT performs\nconsistently with a higher F1 score, accuracy, lower overhead,\nand clearly outperforms ARIMA and RRCF when observing\narea/overhead . The area/overhead of ARIMA and RRCF\nare similar, though ARIMA does show a small improvement\nas\u03b1increases.\nThe difference between the area/overhead of FFT compared\nwith that of ARIMA and RRCF is \u22650.9 in all cases, thus we\nconclude that FFT outperforms both ARIMA and RRCF and\npropose FFT as the algorithm to implement in C HIMBUKO .\nVII. R ELATED WORK\nAs unsupervised ML methods are able to continuously process\ndata, make decisions, and adapt to changing statistics, they\nare a good fit for real-time anomaly detection in streaming\ndata [13].\nMany algorithms chosen to detect anomalies in streaming data\nemploy simple and lightweight statistical techniques [3] in-\ncluding hypothesis testing [20], wavelet analysis [15], Singular\nValue Decomposition (SVD) [16], ARIMA [28], and FFT [23].\nFFT [23] is a statistical method which performs well in real\ntime anomaly detection and is frequently used in the domain of\nvisual computing [10]. Rasheed et al. [18] used FFT to perform\noutlier detection in spatial data by discovering regions of high\nfrequency change. Hansheng et al. [19] leveraged the Spectral\nResidual (SR) model from the visual computing domain for to\ndetect anomalies in real time series data. However, they also\nincorporate CNN in their approach which is not lightweight\nwith 3 modules. Moreover, they focused their efforts on F1\nscore and accuracy at the expense of overhead. Lili et al. [27]\nused fractional FFT with the RX algorithm to detect anomalies\nin hyperspectral images with multi-pixel objects, but this\napproach is limited to the visual computing domain and not\ngeneralizable to real time data.\nThe use of FFT in many recent contributions in anomaly\ndetection can be attributed to both its relatively simple nature\nand applicability to time series data. IBM\u2019s Maximo AssetManagement [2], uses a fast fourier transform based anomaly\ndetector. They treat data from devices as a signal and use\nFFT for pattern extraction, detecting anomalies in the signal\naccording to a scoring function.\nAnomaly detection algorithms have been proposed to reduce\nor remove negative effects caused by assumptions about the\nstatistics of data. ARIMA [3] detects anomalies in data us-\ning temporal information. Bianco et al. have used ARIMA\nsuccessfully to model seasonal time series data [4]. Several\nworks have used ARIMA to predict anomalies in network\ntraffic [26], [25], [17]. RRCF [9] uses a random data structure\nto detect anomalies in real time dynamic streaming data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2886, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad192068-9a0a-45d0-b8bd-9f24df73b9d3": {"__data__": {"id_": "ad192068-9a0a-45d0-b8bd-9f24df73b9d3", "embedding": null, "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3183f3-76e1-4826-a144-f839e72a2072", "node_type": "4", "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "e651456fb488c659dd20369f930a3707598369e928a4ecf89738f95203ae362b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e018cb5-4924-430b-a91a-d194015eb6a9", "node_type": "1", "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "1e7f3e9faea80c6b03e7ccef0e3c1ca120a8a035c68c8033755d526916e16d42", "class_name": "RelatedNodeInfo"}}, "text": "The use of FFT in many recent contributions in anomaly\ndetection can be attributed to both its relatively simple nature\nand applicability to time series data. IBM\u2019s Maximo AssetManagement [2], uses a fast fourier transform based anomaly\ndetector. They treat data from devices as a signal and use\nFFT for pattern extraction, detecting anomalies in the signal\naccording to a scoring function.\nAnomaly detection algorithms have been proposed to reduce\nor remove negative effects caused by assumptions about the\nstatistics of data. ARIMA [3] detects anomalies in data us-\ning temporal information. Bianco et al. have used ARIMA\nsuccessfully to model seasonal time series data [4]. Several\nworks have used ARIMA to predict anomalies in network\ntraffic [26], [25], [17]. RRCF [9] uses a random data structure\nto detect anomalies in real time dynamic streaming data.\nRecent works [24], [7], have used RRCF to detect anomalies\nin streaming and time series data.\nAn algorithm\u2019s robustness, speed, and ability to scale are\ncritical design considerations in real-time anomaly detec-\ntion [21]. In ARIMA, detection of seasonal patterns is time\nconsuming [21]. C HIMBUKO [12] provides speed and an\nability to scale by considering only execution time in detection\nof performance anomalies while using HBOS for real-time\nanalysis. This work extends anomaly detection in C HIMBUKO\nby additionally considering hardware performance counters\nwithout significantly increasing computational or memory\noverhead.\nVIII. C ONCLUSIONS\nIn this paper, we proposed a lightweight anomaly detection\ntechnique based on FFT for real-time data from production\napplications like C HIMBUKO . We compare its performance\nwith two different anomaly detection techniques from ma-\nchine learning and statistics domains on benchmark real-time\ndatasets and real-time data from the production application\nCHIMBUKO . We also used a new metric to compare the\nperformance of anomaly detection with real-time production\napplications to take into account the trade-off between ac-\ncuracy, F1 score, and overhead. FFT consistently performs\nbetter than both ARIMA and RRCF and incurs negligible\noverhead. We limited our comparisons to these 3 algorithms as\nother algorithms will have a larger overhead rendering them\nunsuitable for real-time data analysis. Our goal was to find\nthe anomaly detection algorithm that balances accuracy and\noverhead for real-time systems, and experiments validated that\nFFT is a good fit for lightweight real-time anomaly detection.\nIX. A CKNOWLEDGEMENT\nThe work was supported in part by the grant DE-SC0022843\nfunded by the U.S. Department of Energy, Office of Science.\nThe work was also supported in part by the Exascale Comput-\ning Project (ECP) funded by the U.S. Department of Energy,\nOffice of Science.\nREFERENCES\n[1] Tau doccumentation. 37:n/a\u2013n/a.\n[2] Ibm maximo asset performance management saas-1\u02d9cloud. 37:n/a\u2013n/a,\n12 2021.\n7", "mimetype": "text/plain", "start_char_idx": 2027, "end_char_idx": 4942, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83a630a3-1294-4c58-93e8-b34f41497f73": {"__data__": {"id_": "83a630a3-1294-4c58-93e8-b34f41497f73", "embedding": null, "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "0a7ca0df5a47a9f3b00e0ba185e4d1ba460cc9d5490c378f20b55a0a010a66a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2", "node_type": "1", "metadata": {}, "hash": "d89f21c5764dabbe2a3d45475e9594013431f51140a84ee04ae9b84894023693", "class_name": "RelatedNodeInfo"}}, "text": "[3] Subutai Ahmad, Alexander Lavin, Scott Purdy, and Zuha Agha.\nUnsupervised real-time anomaly detection for streaming data.\nNeurocomputing, 262:134\u2013147, 2017. Online Real-Time Learning\nStrategies for Data Streams.\n[4] A.M. Bianco, M. Garc \u00b4\u0131a Ben, E.J. Mart \u00b4\u0131nez, and V .J. Yohai. Outlier\ndetection in regression models with arima errors using robust estimates.\nJournal ofForecasting, 20(8):565 \u2013 579, 2001. Cited by: 81.\n[5] C. Chatfield and D. L. Prothero. Box-jenkins seasonal forecasting:\nProblems in a case-study. Journal oftheRoyal Statistical Society: Series\nA(General), 136(3):295\u2013315, 1973.\n[6] Ewa Deelman, Tom Peterka, Ilkay Altintas, Christopher D Carothers,\nKerstin Kleese van Dam, Kenneth Moreland, Manish Parashar, Lavanya\nRamakrishnan, Michela Taufer, and Jeffrey Vetter. The future of\nscientific workflows. The International Journal ofHigh Performance\nComputing Applications, 32(1):159\u2013175, 2018.\n[7] Minjung Gim, Jin-Hwan Cho, and Dong Heon Cheo. Anomaly detection\nin sensing data based on rrcf.\n[8] Markus Goldstein and Andreas Dengel. Histogram-based outlier score\n(hbos): A fast unsupervised anomaly detection algorithm. KI-2012:\nposter anddemo track, 9, 2012.\n[9] Sudipto Guha, Nina Mishra, Gourav Roy, and Okke Schrijvers. Robust\nrandom cut forest based anomaly detection on streams. In Maria Flo-\nrina Balcan and Kilian Q. Weinberger, editors, Proceedings ofThe\n33rd International Conference onMachine Learning, volume 48 of\nProceedings ofMachine Learning Research, pages 2712\u20132721, New\nYork, New York, USA, 20\u201322 Jun 2016. PMLR.\n[10] Xiaodi Hou and Liqing Zhang. Saliency detection: A spectral residual\napproach. In InProc. IEEE Conference onComputer Vision andPattern\nRecognition CVPR \u201907, pages 1\u20138, 2007.\n[11] Christopher Kelly, Sungsoo Ha, Kevin Huck, Hubertus Van Dam, Line\nPouchard, Gyorgy Matyasfalvi, Li Tang, Nicholas D\u2019Imperio, Wei Xu,\nShinjae Yoo, et al. Chimbuko: A workflow-level scalable performance\ntrace analysis tool. In ISA V\u201920 InSitu Infrastructures forEnabling\nExtreme-Scale Analysis andVisualization, pages 15\u201319. 2020.\n[12] Christopher Kelly, Sungsoo Ha, Kevin Huck, Hubertus Van Dam, Line\nPouchard, Gyorgy Matyasfalvi, Li Tang, Nicholas D\u2019Imperio, Wei Xu,\nShinjae Yoo, and Kerstin Kleese Van Dam. Chimbuko: A workflow-\nlevel scalable performance trace analysis tool.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2317, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2": {"__data__": {"id_": "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2", "embedding": null, "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "0a7ca0df5a47a9f3b00e0ba185e4d1ba460cc9d5490c378f20b55a0a010a66a0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83a630a3-1294-4c58-93e8-b34f41497f73", "node_type": "1", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "2d3fe7484d446d2607b2a37f4f95670a484b8e49eaaeb410bf6631d4b041bac1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "245770b6-5f44-4dcb-a473-a3aa726177bc", "node_type": "1", "metadata": {}, "hash": "4b072bbeac06e1059ccc77e04b637d5317e29db3161f3dc26b6feee7737ca5c0", "class_name": "RelatedNodeInfo"}}, "text": "[11] Christopher Kelly, Sungsoo Ha, Kevin Huck, Hubertus Van Dam, Line\nPouchard, Gyorgy Matyasfalvi, Li Tang, Nicholas D\u2019Imperio, Wei Xu,\nShinjae Yoo, et al. Chimbuko: A workflow-level scalable performance\ntrace analysis tool. In ISA V\u201920 InSitu Infrastructures forEnabling\nExtreme-Scale Analysis andVisualization, pages 15\u201319. 2020.\n[12] Christopher Kelly, Sungsoo Ha, Kevin Huck, Hubertus Van Dam, Line\nPouchard, Gyorgy Matyasfalvi, Li Tang, Nicholas D\u2019Imperio, Wei Xu,\nShinjae Yoo, and Kerstin Kleese Van Dam. Chimbuko: A workflow-\nlevel scalable performance trace analysis tool. In ISA V\u201920 InSitu\nInfrastructures forEnabling Extreme-Scale Analysis andVisualization,\nISA V\u201920, page 15\u201319, New York, NY , USA, 2020. Association for\nComputing Machinery.\n[13] Alexander Lavin and Subutai Ahmad. Evaluating real-time anomaly\ndetection algorithms \u2013 the numenta anomaly benchmark. In 2015 IEEE\n14th International Conference onMachine Learning and Applications\n(ICMLA), pages 38\u201344, 2015.\n[14] Alexander Lavin and Subutai Ahmad. \u201devaluating real-time anomaly\ndetection algorithms \u2013 the numenta anomaly benchmark\u201d, fourteenth\ninternational conference on machine learning and applications. 37:n/a\u2013\nn/a, 12 2015.\n[15] Wei Lu and Ali A. Ghorbani. Network anomaly detection based on\nwavelet analysis. EURASIP J.Adv. Signal Process, 2009, jan 2009.\n[16] Ajay Mahimkar, Zihui Ge, Jia Wang, Jennifer Yates, Yin Zhang, JoanneEmmons, Brian Huntley, and Mark Stockert. Rapid detection of\nmaintenance induced changes in service performance. In Kenjiro Cho\nand Mark Crovella, editors, Proceedings ofthe2011 Conference on\nEmerging Networking Experiments and Technologies, Co-NEXT \u201911,\nTokyo, Japan, December 6-9, 2011, page 13. ACM, 2011.\n[17] Eduardo H. M. Pena, Marcos V . O. de Assis, and Mario Lemes Proenc \u00b8a.\nAnomaly detection using forecasting methods arima and hwds. In 2013\n32nd International Conference oftheChilean Computer Science Society\n(SCCC), pages 63\u201366, 2013.\n[18] Faraz Rasheed, Peter Peng, Reda Alhajj, and Jon Rokne. Fourier\ntransform based spatial outlier mining. In Emilio Corchado and Hujun\nYin, editors, Intelligent Data Engineering and Automated Learning -\nIDEAL 2009, pages 317\u2013324, Berlin, Heidelberg, 2009. Springer Berlin\nHeidelberg.\n[19] Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang,\nXiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. Time-\nseries anomaly detection service at microsoft.", "mimetype": "text/plain", "start_char_idx": 1735, "end_char_idx": 4159, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "245770b6-5f44-4dcb-a473-a3aa726177bc": {"__data__": {"id_": "245770b6-5f44-4dcb-a473-a3aa726177bc", "embedding": null, "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "0a7ca0df5a47a9f3b00e0ba185e4d1ba460cc9d5490c378f20b55a0a010a66a0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2", "node_type": "1", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "bd8f427138988a9a997f3653e9dd144eac659c861307e83eec41aef216c142d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4f0952a-9324-4044-ac57-7584cbae109a", "node_type": "1", "metadata": {}, "hash": "d4b9313903156103597ca8f4a96711ef29423967e9607e3528f30c789f1337c4", "class_name": "RelatedNodeInfo"}}, "text": "Anomaly detection using forecasting methods arima and hwds. In 2013\n32nd International Conference oftheChilean Computer Science Society\n(SCCC), pages 63\u201366, 2013.\n[18] Faraz Rasheed, Peter Peng, Reda Alhajj, and Jon Rokne. Fourier\ntransform based spatial outlier mining. In Emilio Corchado and Hujun\nYin, editors, Intelligent Data Engineering and Automated Learning -\nIDEAL 2009, pages 317\u2013324, Berlin, Heidelberg, 2009. Springer Berlin\nHeidelberg.\n[19] Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang,\nXiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. Time-\nseries anomaly detection service at microsoft. In Proceedings ofthe\n25th ACM SIGKDD International Conference onKnowledge Discovery\nData Mining, KDD \u201919, page 3009\u20133017, New York, NY , USA, 2019.\nAssociation for Computing Machinery.\n[20] Bernard Rosner. Percentage points for a generalized esd many-outlier\nprocedure. Technometrics, 25(2):165\u2013172, 1983.\n[21] Meir Toledano, Ira Cohen, Yonatan Ben-Simhon, and Inbal Tadeski.\nReal-time anomaly detection system for time series at scale. In Archana\nAnandakrishnan, Senthil Kumar, Alexander Statnikov, Tanveer Faruquie,\nand Di Xu, editors, Proceedings oftheKDD 2017: Workshop on\nAnomaly Detection inFinance, volume 71 of Proceedings ofMachine\nLearning Research, pages 56\u201365. PMLR, 14 Aug 2018.\n[22] Granville Tunnicliffe Wilson. Time series analysis: Forecasting and\ncontrol,5th edition, by george e. p. box, gwilym m. jenkins, gregory\nc. reinsel and greta m. ljung, 2015. published by john wiley and sons\ninc., hoboken, new jersey, pp. 712. isbn: 978-1-118-67502-1. Journal of\nTime Series Analysis, 37:n/a\u2013n/a, 03 2016.\n[23] Charles Van Loan. Computational Frameworks fortheFast Fourier\nTransform. Society for Industrial and Applied Mathematics, 1992.\n[24] Qifan Wang, Bo Yan, Hongyi Su, and Hong Zheng. Anomaly detection\nfor time series data stream. In 2021 IEEE 6thInternational Conference\nonBigData Analytics (ICBDA), pages 118\u2013122, 2021.\n[25] Asrul H. Yaacob, Ian K.T. Tan, Su Fong Chien, and Hon Khi Tan.\nArima based network anomaly detection. In 2010 Second International\nConference onCommunication Software andNetworks, pages 205\u2013209,\n2010.\n[26] H. Zare Moayedi and M.A. Masnadi-Shirazi. Arima model for net-\nwork traffic prediction and anomaly detection. In 2008 International\nSymposium onInformation Technology, volume 4, pages 1\u20136, 2008.", "mimetype": "text/plain", "start_char_idx": 3533, "end_char_idx": 5906, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c4f0952a-9324-4044-ac57-7584cbae109a": {"__data__": {"id_": "c4f0952a-9324-4044-ac57-7584cbae109a", "embedding": null, "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "0a7ca0df5a47a9f3b00e0ba185e4d1ba460cc9d5490c378f20b55a0a010a66a0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "245770b6-5f44-4dcb-a473-a3aa726177bc", "node_type": "1", "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}, "hash": "6a2094211c6853fa73e0ecf2603aff9809ee2dfa7c7abf63da2f7d1224af18b7", "class_name": "RelatedNodeInfo"}}, "text": "Society for Industrial and Applied Mathematics, 1992.\n[24] Qifan Wang, Bo Yan, Hongyi Su, and Hong Zheng. Anomaly detection\nfor time series data stream. In 2021 IEEE 6thInternational Conference\nonBigData Analytics (ICBDA), pages 118\u2013122, 2021.\n[25] Asrul H. Yaacob, Ian K.T. Tan, Su Fong Chien, and Hon Khi Tan.\nArima based network anomaly detection. In 2010 Second International\nConference onCommunication Software andNetworks, pages 205\u2013209,\n2010.\n[26] H. Zare Moayedi and M.A. Masnadi-Shirazi. Arima model for net-\nwork traffic prediction and anomaly detection. In 2008 International\nSymposium onInformation Technology, volume 4, pages 1\u20136, 2008.\n[27] Lili Zhang, Jiachen Ma, Baozhi Cheng, and Fang Lin. Fractional fourier\ntransform-based tensor rx for hyperspectral anomaly detection. Remote\nSensing, 14(3), 2022.\n[28] Yin Zhang, Zihui Ge, Albert Greenberg, and Matthew Roughan. Net-\nwork anomography. In Proceedings ofthe5thACM SIGCOMM\nConference onInternet Measurement, IMC \u201905, page 30, USA, 2005.\nUSENIX Association.\n8", "mimetype": "text/plain", "start_char_idx": 5257, "end_char_idx": 6283, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"aef3d136-e810-4a01-890d-83b6e42d8194": {"node_ids": ["eb078313-8dfc-4f8b-b135-99bf24d6949b", "0d9c38a4-bacf-4c86-943f-b6f309a04c03"], "metadata": {"page_label": "1", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "8712f75a-4d8d-48eb-8ab5-519f872c10a5": {"node_ids": ["2574a6e4-128c-4b72-be10-b3db7e1599c0", "4a19e693-31c6-494d-85c2-fa2068708566", "2a37f814-f9e3-45b9-98fd-5d0da4ecf6ae"], "metadata": {"page_label": "2", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "f16f7a1c-9faa-4347-9a13-bb232b5ecfbc": {"node_ids": ["e1388bac-3ed2-44ad-8f6e-828eb88104fc", "314c83b2-1f4f-462f-a9df-fe7092dae963", "ffdcc9e5-0b39-4810-9fd2-4e1e047f9d93"], "metadata": {"page_label": "3", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "cad11c4f-1cb8-424c-b402-6bfb80fa14a8": {"node_ids": ["90a4a35a-5af3-4b50-8ba4-3ea57a9a648f", "b0f04e2d-60e8-48eb-8cbe-2be79efa511a"], "metadata": {"page_label": "4", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "65828a06-9dcc-4816-9fe2-c6d04307f32a": {"node_ids": ["7697aa0e-f7e0-49ba-a9fa-f055ba16c5c1", "5ee5b3b8-eac7-468a-a175-1d60b9b61465"], "metadata": {"page_label": "5", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "8ec0be30-36cf-4e97-9b25-8f4842f64eb6": {"node_ids": ["d263903d-97d5-411d-a83e-05a3c33133d4", "6c466e67-ce9d-4a4e-ab96-2c2efde0926f", "c732c7a9-eaa6-453c-ae3c-1ed606da68d7"], "metadata": {"page_label": "6", "file_name": "2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/2024_COMPSAC_ldrd_arunavo-1-1.pdf", "file_type": "application/pdf", "file_size": 780750, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "ac142b52-8eb9-4888-b5a3-25287bfef816": {"node_ids": ["111df506-7ad6-456a-afbc-2735fb3a9a8f", "d4215fab-1246-4e21-853d-53d3243b1dcf"], "metadata": {"page_label": "1", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "0a3f0dae-fb8d-4da5-89f8-5aec8b0fa21a": {"node_ids": ["4cbcc6cb-a133-4f99-8840-4fab42e312eb", "57a9ea42-5b75-4bcc-9244-688421dd01b6"], "metadata": {"page_label": "2", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "c325e890-cc06-41dc-bb94-176cace6b10a": {"node_ids": ["6b17472d-dc4b-46c8-8e97-61feb135c6db", "d932e14b-f4a5-47c2-b590-5f5b2efe89b3"], "metadata": {"page_label": "3", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "8e35081f-bd3c-4909-a3a0-8c2c7e327df1": {"node_ids": ["8921507e-616c-4489-b81c-f7b24ff0031a", "97398f38-f881-4e86-a3a9-1f62e0bc5bdc"], "metadata": {"page_label": "4", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "8c901dae-b4d8-461f-b233-aa9dbe34ca9c": {"node_ids": ["7c0ad5c5-cb17-4ab3-a3b0-3f7661e62d6e", "bc8d3c3a-8ae9-4bb3-a8f9-9d8be58b074d"], "metadata": {"page_label": "5", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "c12de919-96a7-44bc-9d9a-0cc878ae3018": {"node_ids": ["ad3c2cc7-4123-4c4c-95db-6e845fb67d31", "43800959-3c1f-4625-8777-69e204f92dba"], "metadata": {"page_label": "6", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "9a3183f3-76e1-4826-a144-f839e72a2072": {"node_ids": ["2e018cb5-4924-430b-a91a-d194015eb6a9", "ad192068-9a0a-45d0-b8bd-9f24df73b9d3"], "metadata": {"page_label": "7", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}, "9a3d8306-c418-41e2-b9f3-ad7f8e6fa24d": {"node_ids": ["83a630a3-1294-4c58-93e8-b34f41497f73", "f38b68cd-2ab6-48c5-a63b-af2ad719b3f2", "245770b6-5f44-4dcb-a473-a3aa726177bc", "c4f0952a-9324-4044-ac57-7584cbae109a"], "metadata": {"page_label": "8", "file_name": "COMPSAC23_Anomaly_Detection-1-1.pdf", "file_path": "/home/ubuntu/Personal/Retrieval-Augmented-Generation-RAG-app-with-LlamaIndex/data/COMPSAC23_Anomaly_Detection-1-1.pdf", "file_type": "application/pdf", "file_size": 4361268, "creation_date": "2024-09-02", "last_modified_date": "2024-09-02"}}}}